[[chap:architecture]]
= Architecture

In this chapter we present our architecture for the processing of large geospatial data in the Cloud. The main goal of our architecture is to provide both GIS users and developers of spatial processing algorithms with the means to leverage the capabilities of the Cloud. Our architecture is scalable and supports processing of arbitrarily large data sets. Its design is based on the microservice architectural style. One of the key points of our architecture is that it enables distributed development. Developers and researchers from different companies and institutions can contribute their processing algorithms and extend the functionality of our system. Due to the modularity of the architecture, such external components can be integrated without fundamental modifications. The architecture is also designed to be fault tolerant and highly available.

The chapter is structured as follows. We first provide the reader with background on Service-Oriented Architectures and the microservice architectural style. We then present existing work and describe how our architecture relates to it. After that, we perform a comprehensive requirements analysis by defining stakeholders that have an interest in our system as well as quality attributes our architecture should meet. The main part of the chapter describes the overall architecture, its components, and how they communicate with each other. We also define a few technical requirements that processing algorithms need to satisfy in order to be integrated into our system. Further, we discuss continuous deployment and operational aspects such as monitoring and logging. We finish the chapter with a summary.

== Background

In this section we discuss two architectural styles of software design that are of major importance for our work: the Service-Oriented Architecture (Section <<sec:architecture-service-oriented-architecture>>) and the microservice architectural style (Section <<sec:architecture-microservice-architectures>>) which emerged from the former and provides the basis for our system.

[[sec:architecture-service-oriented-architecture]]
=== Service-Oriented Architecture

Service-Oriented Architecture (SOA) describes a style of designing a distributed application with loosely coupled components (services) communicating over network protocols, in contrast to a monolithic application where components are tightly coupled and communicate through function calls inside the same process space. The main goal of SOA is to provide means to create large distributed systems that are scalable and flexible. For lack of a common and concise definition for SOA, citet:Footen2008[] have created the following one:

[quote]
____
SOA is an architecture of independent, wrapped services communicating via published interfaces over a common middleware layer.
____

citet:Josuttis2009[] proposes employing an Enterprise Service Bus (ESB) as the middleware layer. An ESB decouples the services, provides a higher degree of interoperability, and reduces the number of communication channels. Instead of communicating directly with each other, the services only need to connect to the ESB. The bus handles network protocols and message routing, and supports multiple message exchange patterns (e.g. asynchronous request/response or publish/subscribe).

Figure <<img-service-oriented-architecture>> depicts a Service-Oriented Architecture with five services connected through a middleware layer. The diagram also shows how an existing software component (often called a _legacy service_) can be integrated into an SOA by providing a wrapper service that handles the communication with the middleware layer on behalf of them. This pattern allows a Service-Oriented Architecture to be implemented in a company incrementally without the need to completely rebuild the company's infrastructure from scratch.

[#img-service-oriented-architecture]
.A Service-Oriented Architecture according to citet:Footen2008[]
image::images/03_architecture/soa.pdf[scaledwidth="60%",align="center"]

The term _Service-Oriented Architecture_ was originally coined by Gartner cite:Schulte1996a,Schulte1996b[]. It gained momentum in the early years of the 21st century with the boom of the Internet and the World Wide Web, which became available to a broad audience. New web technologies and network protocols made it easier to create an application of distributed loosely coupled services. Major drivers were technologies such as HTTP, XML, and SOAP. Large companies such as IBM, Oracle, HP, SAP and Sun joined the momentum and created a whole ecosystem around SOA consisting not only of tools, technologies, and design patterns on the technical level, but also extending to the business level where common enterprise roles, policies and processes were defined. This created criticism by people who considered SOA just a hype and a buzzword with which IT vendors tried to make money by selling concepts and tools or simply rebranding old ones cite:Josuttis2009[prefix=cf.].

Due to the fact that SOA and the World Wide Web experienced a boom almost at the same time, a Service-Oriented Architecture was (and still is) often considered equivalent to a distributed web application consisting of web services. However, citet:Yefim2003[] states the following:

[quote]
____
[&hellip;] Web services do not necessarily translate to SOA, and not all SOA is based on Web services [&hellip;]
____

SOA should rather be seen as the continuation of object-oriented programming (OOP) on a higher level. Much like OOP is used to modularise programs, SOA can be used to split a large application into a set of distributed services, each of them having their own responsibilities. Whether these services use web technologies or not is actually irrelevant. According to the Open Group's definition of SOA cite:Footen2008[locator=72], a service is a component that has the following properties:

* It is self-contained
* It may be composed of other services
* It is a black box to consumers of the service

Most of the services we describe in our work--in particular the processing services (see Section&nbsp;<<sec:architecture-processing-services>>)&mdash;are not web services but still have these properties.

The fact that people confused SOA with web services, as well as the criticism around exploiting the term commercially, led to a constant decline of popularity. In addition, the policies and business processes specified and promoted by large IT vendors often did not match the structures of other organisations. On a technical level, SOA imposed a couple of limitations. An enterprise service bus does not always fit in any distributed application. Technologies such as XML and SOAP were considered too heavy, too complex, and out of date compared to their more modern and lightweight counterparts JSON and REST.

With the advent of Cloud Computing a more flexible way to create large distributed systems was required. This led to the creation of the microservice architectural style.

[[sec:architecture-microservice-architectures]]
=== Microservice architectural style

The term _microservice_ is not clearly defined in the literature yet. The British software engineer Martin Fowler citey:fowler2014[] describes it as follows:

[quote]
____
In short, the microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies.
____

According to this, an application based on microservices is--as opposed to a large monolith--split into small pieces acting in concert to serve a larger purpose. Each of these pieces is developed, maintained, and deployed independently. Microservices have the following characteristics:

[role="mt-1"]
**Size and focus.** Each microservice typically serves one specific purpose. For example, a distributed system used in a supply company may contain a service for customer management, one for stock management, and another one for the processing of orders. The boundaries between microservices are often drawn along so-called _Bounded Contexts_ which are identified while specifying the application's architecture using _Domain-driven Design_ as described by citet:evans2003[].

[role="mt-1"]
**Independence.** Microservices are _separated_ from each other or _autonomous_ cite:newman2015[]. They run in their own processes--often even in separate virtual machines or containers. They offer interfaces to other services and communicate through lightweight protocols such as an HTTP API as described above. The fact that they run in their own processes also means they are separated programs and projects. They are developed independently and often by different people or teams. These teams use the technologies and programming languages they are familiar with but not necessarily the same as other teams working on the same distributed application. One of the biggest advantages of this separation is the fact that microservices can be deployed to production independently. This means new features and bug fixes can be made available to customers in a short amount of time and without affecting the overall availability of the distributed application.

[role="mt-1"]
**Scalability and fault tolerance.** Modern distributed applications need to be _scalable_ to be able to handle large amounts of users and data. They also need to be _resilient_ to external influences such as a quickly growing number of customers (e.g. on busy shopping days such as the Black Friday in the U.S. or before Christmas), as well as failing components (e.g. broken hardware, unstable network connection or crashed software components). Microservices can help implement a scalable and resilient system. They are deployed in a distributed manner and typically redundantly. Peaks in demand can be handled by adding more service instances. If one of them should fail or become unavailable--for whatever reason--other instances can take over. In any case, even if all instances of a microservice should fail, the impact on the rest of the application is minimized.

[role="mt-1"]
**Organisational patterns.** According to _Conway's Law_, "`organizations which design systems [&hellip;] are constrained to produce designs which are copies of the communication structures of these organizations`" cite:conway1968[]. This means the architecture of any software mirrors the structure of the organization developing it. For example, if you assign five teams to develop a distributed application you will most likely get an architecture consisting of five different services communicating with each other. Microservices match this concept very well. As described above, they are developed independently by different teams. Each team is responsible for one or more microservices, but one service never falls into the responsibility of more than one team. In projects where many parties provide services, this approach helps keep responsibilities clear and enables distributed collaboration.

[role="mt-1"]
**Composability.** Microservices are _composable_ and _replaceable_. Multiple microservices act in concert and make up a larger application. Single services may be reused in different applications or in different areas of the same application. In addition, since microservices are small and serve only one purpose they can be easily replaced, for example, if they are updated to a new technology stack, or if a newer service version provides an improved algorithm or better security.

[role="mt-1"]
The microservice architectural style is quite similar to the approach of a _Service-Oriented Architecture_. There are subtle differences, particularly in terms of the actual implementation of a distributed application and guidelines for how to design the architecture. Sam Newman citey:newman2015[locator='9, first paragraph'] summarises the differences as follows:

[quote]
____
The microservice approach has emerged from the real-world use, taking our better understanding of systems and architecture to do SOA well. So you should instead think of microservices as a specific approach for SOA in the same way that XP or Scrum are specific approaches for Agile software development.
____

A microservice architecture is therefore a Service-oriented Architecture. The difference is most apparent in the way services are deployed and executed. While SOA defines that an application should consist of services, it does not define how they should be run. In an SOA services may still be part of a single monolithic application (often running inside an application container such as Apache Tomcat) whereas the microservice architectural style demands that these services must run in separate processes and be deployed independently. The microservice approach therefore goes one step further and gives guidance and concrete instructions in areas where SOA is lacking clarity cite:newman2015[].

In a microservice architecture a middleware layer does not play such an important role as in an SOA. If necessary, an ESB can still be used--but it is not required--which allows developers to create more flexible and arbitrary networks of services. The microservice architectural style also does not specify policies and business processes that enterprises must follow. It is therefore a more lightweight approach than a full-fledged SOA and mostly applies at the technical level without impinging on the way companies conduct their business.

While the microservice approach has many advantages, it also comes with a couple of drawbacks. For example, the application's complexity increases with the growing number of services. This problem is known from monolithic applications whose complexity increases with the number of classes or components, but is further aggravated by the fact that the services are distributed and have to communicate over a network that may be unreliable cite:deutsch1994[prefix=see].

The complexity can be tackled by decomposing an application vertically according to bounded contexts. Figure&nbsp;<<img-microservices>> compares a typical monolithic application to a software architecture based on microservices. The standard way to implement a monolithic application is to divide it into three tiers, namely the data tier, the logic tier and the presentation tier (Figure&nbsp;<<img-microservices>>a). An application based on Microservices is a set of loosely coupled services communicating with each other (Figure&nbsp;<<img-microservices>>b). The larger the application becomes, the more important it will be to order the services. Figure&nbsp;<<img-microservices>>c shows how an application can be decomposed vertically along bounded contexts. That means that services belonging to the same context (such as those managing customers, stock and orders, as well as those dealing with employees and internal accounting) should be grouped and only a couple of services are allowed to communicate with services from other bounded contexts.

[#img-microservices.top]
.Comparing a monolithic software architecture with two approaches to system decomposition based on microservices
image::images/03_architecture/microservices.pdf[scaledwidth="100%",align="center"]

For our work, the microservice architecture style is beneficial as it allows us to create a system that is very flexible, scalable and fault-tolerant. As we will show in Section <<sec:architecture-stakeholders>>, services in our architecture can be developed by teams distributed over multiple countries. The microservice architectural style allows these teams to work independently and yet integrate their services into a single system. Furthermore, microservices can be reused and composed in different ways in order to satisfy varying requirements. This property is essential for our work, because it allows us to orchestrate services to complex spatial processing workflows.

== Related work

After we discussed relevant architectural styles for software design in the previous section, we now review the literature relevant to our work. We first show how microservice architectures are used in the scientific community to build various systems. Then we discuss software architectures for distributed data processing as well as geospatial applications in the Cloud. Finally, we provide an overview of relevant work combining these two areas, namely the processing of geospatial data in the Cloud.

[[sec:architecture-related-work-microservice-architectures]]
=== Microservice architectures

Since the advent of microservices and their broader acceptance within the industry and also the scientific community, the number of publications on this topic has increased quickly. One of the most influential work on microservices is the book "`Building microservices`" by citet:newman2015[]. The book touches many aspects related to microservices ranging from how to model services and how to integrate them into larger systems, up to operational topics such as deployment and monitoring.

The microservice architectural style has significant benefits over the traditional way of designing an application as a monolith. citet:Villamizar2015[] compare both approaches and specifically focus on applications in the Cloud. They argue that monolithic applications are often not designed to be run in the Cloud and therefore cannot handle dynamic infrastructure changes. A microservice architecture, on the other hand, is more flexible and scalable as individual services can be deployed and relocated on demand during runtime. citea:Villamizar2015[] state that there are a number of factors that can increase the complexity of a system: the number of services, the number of involved developers and teams, the number of operators, and the number of targeted business applications. They claim that the microservice architectural style can help tackle the complexity. As we will describe in Section <<sec:architecture-stakeholders>>, we have similar issues in our architecture, in particular since we have a large number of services (more than a hundred, see Chapter <<chap:evaluation>>) and many distributed development teams.

citea:Villamizar2015[] also describe challenges linked to the microservice architectural style. The development of a system of distributed services can sometimes be hard because issues such as network failures or timeouts need to be considered. In addition, team management processes should be adapted to this new style of system development. This is, however, not just a drawback but can also be a chance to increase efficiency in development and collaboration between developers and teams. citet:Balalaie2016[], for example, report on their experience with applying the microservice architectural style and methods from the DevOps movement cite:Loukides2012[] to the development of an application providing data management functionality to mobile developers. They formed small cross-functional teams--each of them being responsible for one service--as well as a core team for shared functionality. They state that one of the main benefits of this approach is a shorter time-to-market. The teams are completely responsible for their service and can deploy it much faster than a traditional team structure consisting of development, quality assurance and operations could. In addition, citea:Balalaie2016[] further state that code written by such small teams has a higher comprehensibility and maintainability, and that new team members can be added with a lower learning curve.

One of the key findings from the work of citea:Balalaie2016[] is that automated deployment plays an important role in a microservice architecture, in particular with a growing number of services and a higher complexity of the infrastructure the services are deployed to. A similar observation is made by citet:Ciuffoletti2015[] who describes a microservice-based monitoring infrastructure and how it can be automatically deployed. He argues that automated deployment can also help transfer an application to different infrastructures for development, testing and operation (portability). In our work we also automate the deployment of our system in order to be able to handle its complexity and the large number of services. Furthermore, we consider portability, in particular to keep the system independent from the infrastructure it is installed on and thus avoid vendor lock-in.

In order to implement the automated deployment, citea:Ciuffoletti2015[] makes use of container technology. Containers have major benefits in terms of isolation and portability of services. However, containerisation is a kind of virtualisation and can affect performance. Independent studies conducted by citet:Amaral2015[] and citet:Kratzke2015[] show that while the impact on CPU power is negligible, network performance inside containers is significantly slower than on the hosting machine (up to 20%). In our architecture we also use container technology to deploy services. Nevertheless, we do not transfer large amounts of data between processing services through the network. Instead, we use a distributed file system as the main communication channel and mount it into the containers when we start them. The communication between compute nodes in the Cloud is managed by the driver of the distributed file system which is not containerised. Since the performance impact on file system I/O operations inside containers is very small cite:Felter2015[] our processing services run almost as fast as if they were not containerised.

One major challenge in applying the microservice architectural style is that with a growing number of services a distributed application can become very complex which may lead to security vulnerabilities. citet:Esposito2016[] state that having multiple services can enlarge the attack surface by offering more vulnerability points. They also argue that the microservice architectural style encourages using off-the-shelf software (such as open-source libraries) and that their trustworthiness should be properly validated and monitored. We discuss some security aspects in Section <<sec:architecture-security>> but a comprehensive security concept is beyond the scope of this work.

Running a microservice architecture in the Cloud is beneficial to many companies, in particular considering the costs in comparison to operating a monolithic application. citet:Villamizar2016[] report on a case study they conducted to compare a monolithic architecture to one based on microservices and another one running serverless on Amazon AWS Lambda. They implemented an example application using these three different architectures and compared performance and response times but particularly focused on the costs. They conclude that microservices can help reduce infrastructure costs tremendously but the increased effort of implementing and maintaining an application based on this architectural style has to be considered carefully.

An approach to manage the effort is presented by citet:Toffetti2015[]. They propose a microservice architecture that enables scalable and resilient self-management of Cloud applications. They employ distributed storage and leader election functionalities of existing tools commonly used in Cloud application development. Their approach allows them to constantly monitor their application and to implement features such as autonomous health management and self-healing. One of the main contributions of their work is that they do not rely on infrastructure provider services and therefore avoid vendor lock-in. They conclude that the microservice architectural style aligns well with their approach.

There are a couple of papers dealing with the experiences from applying microservices to practical use cases. For example, citet:vianden-lichter-steffens-2014[] present a reference architecture for Enterprise Measurement Infrastructures (EMIs) as well as two case studies in which they apply this architecture to an EMI monitoring software development and another one collecting risk metrics in IT projects. They argue that systems based on classic SOA suffer from centralized integration problems such as the need for a common data schema and related mapping issues. To avoid these problems, they divide their EMI into dedicated microservices for measurement, calculation and visualization. Their results look promising and they suggest further long-term field studies.

citet:Alpers2015[] present a microservice-based architecture to create tool support for business process modelling and analysis. They claim that the microservice architectural style improved the scalability of their system, and that additional or different functionality could be easily implemented.

The microservice architectural style has also been applied to data-driven workflow management. citet:Safina2016[] present Jolie, a programming language to formalise the composition of microservices to create data-driven workflows. They claim that their approach helps identify common communication patterns in microservice architectures, which opens opportunities for new programming scenarios.

For supplemental information on the state of the art and publications related to microservices we refer to the work by citet:Alshuqayran2016[] who present a systematic study on the research conducted in this field including architectural challenges faced by the community, diagrams used to represent microservice architectures, as well as involved quality requirements. In addition, citet:DiFrancesco2017[] present results from a thorough review of the literature on the microservice architectural style. They specifically evaluate existing work from three perspectives: publication trends, focus of research, and potential for industrial adoption. They state that most publications on microservices are of a practical nature and that they present specific solutions. They also claim that the research field is still immature and that most of the studies they reviewed are far away from being transferred to industrial use. However, they note that the "`balanced involvement of industrial and academic authors is [&hellip;] promising for knowledge co-creation and cross-fertilization`".

=== Architectures for Big Data processing

There are a couple of architectural patterns that are often used for Big Data processing applications. Each of these patterns targets specific use cases and has different benefits and drawbacks. In this section we review the most prominent approaches and compare them to ours.

==== Batch processing

[#img-data-processing-batch]
.A batch processing architecture
image::images/03_architecture/data-processing-batch.pdf[scaledwidth="100%",align="center"]

Batch processing works well for applications where data is first acquired and subsequently processed. The processing pipeline is depicted in Figure <<img-data-processing-batch>>. The data is collected from one or more data sources and then put into a data store. The processing can be triggered any time and operates on the whole set of collected data or on a smaller batch of it. It can potentially happen in an iterative way. Intermediate results are written back into the store, but the original data is never changed. Final results are sent to a serving layer which produces a result view for consumers to query.

A typical programming pattern for batch processing is MapReduce cite:Dean_Ghemawat_2008[] which makes batch processing very scalable. It can handle arbitrary data volumes and can be scaled out by adding more resources--typically compute nodes. The most popular frameworks for batch processing are Hadoop and Spark. Tools such as HBase, Imapala, or Spark SQL can be used to implement the serving layer and to provide interactive queries on the result view.

==== Stream processing

[#img-data-processing-stream]
.A real-time stream processing architecture
image::images/03_architecture/data-processing-stream.pdf[scaledwidth="100%",align="center"]

One drawback of batch processing is that it can take a long time (a couple of hours or even longer) if the input data set is very large. Applications that have to provide information in near real-time need a faster approach. In a stream processing system as depicted in Figure <<img-data-processing-stream>>, incoming data is handled immediately. A stream-oriented processing pipeline is event-driven and has a very low latency. Results are typically produced in the order of less than a second. In order to achieve this, the result view in the serving layer is updated incrementally.

Immediately processing each and every single event can introduce overhead. Some stream systems therefore implement a micro-batching approach where events are collected to very small batches that can still be processed in near real-time.

Typical frameworks for stream processing are Spark Streaming, Storm, or Samza. Data storage solutions that support incremental updates and interactive queries are Cassandra and Elasticsearch.

==== Lambda architecture

[#img-data-processing-lambda]
.The Lambda architecture
image::images/03_architecture/data-processing-lambda.pdf[scaledwidth="100%",align="center"]

While stream processing can provide results in a short time, it is not very resilient to changes in the processing algorithm code. Such changes can happen if there was a bug in the code or if requirements have changed and additional values need to be computed from the input data set. Batch processing allows the result view to be recomputed by processing the whole data set again. In the stream processing approach, on the other hand, there is no store for input data and hence recomputing is not possible. A bug in the processing code can corrupt the incremental result view without a way to make it consistent again.

In order to combine the benefits of both approaches--the fault-tolerance of batch processing and the speed of stream processing--Nathan Marz has created the Lambda architecture for Big Data processing cite:marz2015[]. In this architecture, input data is sent to a batch layer and a so-called speed layer at the same time (see Figure <<img-data-processing-lambda>>). Both layers implement the same processing logic. The batch layer is used to process large amounts of data and to regularly reprocess the whole input data store. The speed layer contains a stream processing system and compensates for the high latency of batch processing. It only calculates results for data that has arrived since the last run of the batch layer.

In the serving layer, the batch results as well as the incremental streaming results are combined to a view that provides a good balance between being up-to-date and correct (i.e. tolerant to errors). Streaming results are discarded as soon as new batch results have been computed.

==== Kappa architecture

[#img-data-processing-kappa]
.The Kappa architecture
image::images/03_architecture/data-processing-kappa.pdf[scaledwidth="100%",align="center"]

Modern stream processing systems are as capable as batch processing systems in terms of functionality and expression power. If they were not, it would actually not be possible to implement a Lambda architecture, where both branches have the same processing logic. Due to this, people have started questioning the usefulness of batch processing in the Lambda architecture. Maintaining two branches with the same logic in two different programming styles can become very complex. The only advantage of batch processing over stream processing is its resilience to programming errors or changing requirements, which is based on the fact that the original input data is permanently kept in a store and recomputing is therefore always possible.

In an attempt to simplify the Lambda architecture, citet:Kreps2014[] has created the Kappa architecture (see Figure <<img-data-processing-kappa>>). This architecture is very similar to a typical stream processing pipeline. However, citea:Kreps2014[] recommends keeping a log of incoming data (or events) which can be replayed and therefore used to recompute the result view if necessary. A typical framework that allows for collecting input data in a log for a certain amount of time (retention period) is Kafka. In order to cover most cases, it is recommended to configure a long retention period of at least several weeks. Since Kafka allows for processing the log from any point and by multiple readers at the same time, recomputing the result view can be done without interrupting near real-time processing.

==== Summary

In this section we have described four of the most common architectures for Big Data processing. The one that is best comparable to ours is batch processing. Although velocity--i.e. the speed in which data is acquired and has to be processed--often plays an important role for geospatial applications, data acquisition and processing are typically separate events with defined start and end points cite:Kitchin2016[prefix=see]. For example, in our urban planning use case described in Section <<sec:introduction-use-case-a>> mobile mapping data is first collected on a hard disk and then uploaded to the Cloud for processing. A similar pattern can be found in our second use case (see Section <<sec:introduction-use-case-b>>) or in applications dealing with satellite imagery.

In contrast to information collected by a social media platform, for example, the acquisition of geospatial data is usually not a continuous process but one that is inherently eventually finished--i.e. as soon as all required data has been collected. The stream processing approach expects data to be collected continuously and aims at processing it at the same time with a short latency. In order for this to work and to meet near real-time constraints in the order of less than a second, the individual processing steps need to be very fast. Geospatial algorithms and the models they operate on are, however, known to be very complex and expected to become even more so in the future cite:Yang2011[]. Near real-time is possible for certain use cases such as the evaluation of readings in a sensor network but not reasonable for every geospatial application.

The architectures presented in this section are typically used to implement very specific use cases and processing pipelines. Our architecture, on the other hand, allows for creating more flexible workflows that can be used for a wider range of purposes. In fact, as we will show later, we can incorporate batch or stream processing into our workflows and thus create pipelines on a much higher level.

=== Cloud architectures for geospatial applications

One of the major research topics in the geospatial community in recent years is modern urban management and the use of supporting information technology. A city that leverages ICT to improve urban development processes is often referred to as a _Smart City_ cite:ludlow-khan-2012[]. To achieve their goal of a sustainable and liveable urban environment, Smart Cities collect and process large amounts of geospatial data. Cloud Computing technology is often used in this context cite:Khan2013_1[].

A major amount of urban data is collected by IoT devices (Internet of Things) distributed all over the city (stationary as well as mobile devices). For example, in-situ sensors produce data about traffic density, air quality or weather that can be used to analyse events in near real-time and to produce plans to counteract negative implications of, for example, recurring traffic jams and their impact on the environment. At the same time, data from mobile devices such as smartphones, tablets or sensors in vehicles can be used to analyse motion patterns of citizens and monitor socio-economic interactions and developments, which helps implement measures eventually leading to a higher quality of life cite:PetersAnders2014[].

citet:Krylovskiy2015[] argue that IoT is one of the key enablers of Smart City applications. They present a software platform which aims at engaging various stakeholders in order to increase the energy efficiency of urban districts. They identify a number of challenges that developers are typically faced with when designing a scalable IoT platform: a large variety of services, constantly evolving technologies, changing requirements, interdisciplinary and international teams, as well as the demand to increase quality while reducing operational costs. They state that there are similar challenges in the development of distributed applications and that the microservice architectural style simplifies the design and implementation of individual services. They also argue that it comes with the cost of a more complex distributed system in which compromises such as eventual consistency are, however, reasonable trade-offs for the gained benefits.

Related publications on Smart City applications in the Cloud often do not specifically focus on data processing and computational power, but also try to leverage other capabilities such as distributed data storage and the possibility to make information accessible at a central location in order to share it with third parties--e.g. other departments or official agencies in the same municipality as well as the public. citet:Khan2012_1[], for example, present an architecture for context-aware citizen services. The main purposes of this architecture are data collection and centralised access. citea:Khan2012_1[] do not use microservices. They divide their system into seven distinct layers ranging from platform integration, data acquisition and analysis, to the actual application. They conclude that the processing and data storage capabilities of Cloud Computing provide a suitable environment for Smart City applications. One of the major benefits of their approach is that information from different sources can be integrated at a central location and enriched with contextual data in order to enhance the experience of citizens with their system.

In parallel with this thesis, we have also explored the use of microservices for Smart City applications, but we specifically focused on secure data storage cite:kraemer-frese-2017[]. We created a distributed application for the assessment of security risks in urban areas. Since such an application has to deal with potentially sensitive data, we presented an approach leveraging attribute-based encryption in order to store large data sets securely in the Cloud, while preserving the possibility to share them with multiple stakeholders. The microservice architectural style helped us to create a scalable and flexible design that can be applied to other use cases too.

Cloud Computing can also be beneficial for geospatial applications in general, not only for Smart Cities. citet:Lee2008[] state that the "`ability to access, integrate, analyse, and present geospatial data across a distributed computing environment [&hellip;] has tremendous value`" but also requires standardised interfaces. They argue that international standards for distributed geospatial applications are required in order to improve interoperability between systems and to ease data access. The OGC (Open Geospatial Consortium) has recently set up a new domain working group for Big Data dealing with Service-Oriented Architectures for the distributed processing of spatial data and the standardisation of related technologies. The architecture we present in this chapter is very flexible and allows for integrating various kinds of processing services. This also includes web processing services such as the OGC WPS. The OGC is of major importance for the geospatial community and we consider the possibility of integrating OGC services into our system an advantage. However, OGC services are web-based and have an HTTP interface. This  means data has to be transferred through HTTP before it can be processed which may impose a certain performance hit. In our architecture we deploy a distributed file system (see Section&nbsp;<<sec:architecture-distributed-file-system>>) to which processing services are directly connected. This allows for a faster data access. Nevertheless, including services such as the OGC WMS (Web Map Service) or WFS (Web Feature Service) as an external data sources can be beneficial if it improves the quality of processing results.

=== Cloud architectures for geospatial processing

While there has been work on Big Data processing as well as on Cloud architectures for geospatial applications, the combination of the two, Cloud architectures for geospatial data processing, has only become subject to research in the last couple of years cite:Cossu2013,Agarwal2012[]. The availability of commercial Cloud solutions such as Amazon Web Services (AWS) or Microsoft Azure has facilitated applications in this area. For example, citet:qazi2013[] describe a software architecture for the modelling of domestic wastewater treatment solutions in Ireland. Their solution is based on AWS on which they install the commercial tool ArcGIS Server via special Amazon Machine Images (AMIs) provided by Esri. citea:qazi2013[] make use of the ArcGIS Server REST interface to deploy web services providing spatial datasets. Additionally, they implement a web application that can be used for decision support. While the focus of their work is on deploying a highly available data storage and a decision support tool, they do not cover the issue of very large geospatial datasets and how the capabilities of Cloud Computing can be exploited to process them. In addition, their work depends on the commercial ArcGIS Server and the respective Amazon Machine Images. Our architecture, on the other hand, does not rely on commercial software and can be configured to run on different infrastructures.

citet:warren2015[] report from their experience from processing over a petabyte of data from 2.8 quadrillion pixels acquired by the US Landsat and MODIS programs over the past 40 years. They claim to be the first researchers who are able to process such a large data set in less than a day. They leverage the Cloud Computing platform from Google. Their processing pipeline consists of 10 steps including uncompressing raw image data, classifying points, cutting tiles, performing coordinate transformations, and storing the results to the Google Cloud Storage. The process is static and highly optimised for the Google platform. The architecture we present, on the other hand, is portable and allows more configurable and parametrisable workflows to be created.

citet:li2010[] leverage the Microsoft Azure infrastructure to process high-volume datasets of satellite imagery in a short amount of time. Their solution consists of a cluster of 150 virtual machine instances which they claim to be almost 90 times faster than a conventional application on a high-end desktop machine. They achieve this performance gain by implementing an algorithm based on reprojecting and reducing. This approach can be compared to MapReduce. However, it was explicitly developed for the Azure API which provides a queue-based task model quite different to MapReduce. Compared to their approach, our work does not focus on one specific processing model. Instead, we describe an architecture that is flexible and facilitates a number of different approaches to distributed algorithm design.

Since a growing number of Cloud infrastructure providers support MapReduce--in particular its open-source implementation Apache Hadoop--the geospatial community has started developing solutions specifically targeted at this. The Esri GIS Tools for Hadoop, for example, include a number of libraries that allow Big Geo Data to be analysed in the Cloud. The libraries are released as open source. They offer a wide range of functionality including analytical functions, geometry types and operations based on the Esri Geometry API. Similar to this, the project SpatialHadoop adds spatial indexes and geometrical data types and operations to Hadoop. While there has been work utilising the Esri GIS Tools for Hadoop and SpatialHadoop cite:Eldawy2013,Ajiy2013[], the MapReduce paradigm implies fundamental changes to geospatial algorithm design as it has been done before. The effort of migrating an existing algorithm to MapReduce often outweighs its advantages. MapReduce is not the only solution to exploit Cloud Computing infrastructures. Other approaches such as actor-based programming or in-memory computing are often more appropriate for certain algorithms and in some cases a lot faster cite:Xin2013[]. Our architecture enables arbitrary algorithms to be executed in the Cloud, which allows developers to select the most appropriate programming paradigm for a specific purpose.

One of the most popular frameworks for distributed data processing that goes beyond MapReduce is Apache Spark. citet:liu2016[] use this framework to detect changes in sets of large LiDAR point clouds. They conclude that Spark is suitable to process data that exceeds the capacities of typical GIS workstations. However, they are not completely satisfied with the results of their processing algorithm and propose adding a postprocessing step to reduce the noise. Solutions such as Hadoop or Spark are suitable to create specific processing algorithms but for workflows where a chain of algorithms is applied (e.g. preprocessing, change detection, and postprocessing) a higher-level solution is necessary. Our architecture allows such workflows to be created. It can control simple services but also processing frameworks such as Hadoop or Spark and integrate them into a workflow.

Since geospatial applications in the Cloud are quite new, the community is still looking for best practices. citet:Agarwal2012[] report from their experience with implementing a Cloud-based system called Crayons that facilitates high-performance spatial processing on the Microsoft Azure infrastructure. They present several lessons learnt ranging from data storage to system design. In particular, they state that a large system should be designed with an open architecture so individual components can be replaced by others without affecting the overall system functionality. Our architecture is service-oriented and consists of loosely coupled components that can be exchanged quite easily. This way, a wide range of spatial processing services are supported and can be extended later without requiring changes to the architecture. Additionally, our approach allows individual components to be replaced if requirements should change in the future.

== Requirements analysis

In this section we describe the requirements that led to our software architecture. We first provide a list of stakeholders and what specific requirements and concerns they wish the system to meet and guarantee. We then describe a set of quality attributes--i.e. properties that the system has to have in order to satisfy the needs of the stakeholders. The requirements and quality attributes were derived from analysing the problem domain in Section <<sec:introduction-problem-statement>>, from our work in various international research projects, as well as our experience from developing GIS products and collaborating with domain users from municipalities, regional authorities, federal agencies, and the industry over the last nine years.

[[sec:architecture-stakeholders]]
=== Stakeholders

In the following we describe various stakeholders who have an interest in a system for the processing of geospatial data in the Cloud. These people have different responsibilities ranging from software development to infrastructure management. We also include stakeholders who use our system to carry out GIS projects, as well as business professionals who have an interest in exploiting the capabilities of our system or the data processed with it.

Note that the stakeholders we present here are not necessarily individual people but roles. Multiple people can have the same role, and a single person can have multiple roles. For example, _members of the system development team_ are often also _integrators_ and _testers_. Additionally, since the DevOps movement cite:Loukides2012[] has become more and more prominent in recent years, the boundaries between software development and IT operations have blurred and _developers_ are now often responsible for _deployment_ and _administration_ too.

We divide people who have an interest in our architecture into roles to get a clearer picture of the domain and to identify individual requirements. However, in our experience component developers need to be involved in integration, deployment and operations in order to better understand how their components need to be designed to work correctly in a distributed environment. This particularly applies to the role of _processing algorithm developers_ who often do not have a background in computer science or programming of distributed applications.

==== Users (GIS experts)

Our system design targets users who are GIS experts. They have diverse backgrounds (i.e. in geography, surveying, geoinformatics, hydrology, etc.) and work for different organisations and authorities such as municipalities, regional authorities, national mapping agencies but also companies dealing with or contributing to geospatial projects. These users work with large datasets that they need to store and process. However, their local workstations often lack hard disk space, main memory, or computational power, and so the storage and processing of large geospatial data is at least challenging or merely impossible.

In addition, the GIS experts often need to share data with their colleagues, with other departments, as well as with other authorities and organisations. This applies to original datasets and processing results. At the same time, they need access to external datasets to combine them with their own data.

In order to perform these tasks, the GIS experts want to harness the capabilities of the Cloud. They need an infrastructure that has enough resources to store large datasets and an interface to share them with other parties. They also want to use the computational power of the Cloud to save time in data processing.

The experts typically use a desktop GIS (e.g. ArcGIS or QGIS) which offers a number of spatial operations and processing algorithms. Most desktop GISs also provide a way to create automated processing workflows. These workflows specify which spatial operations should be applied to a dataset in order to produce a certain result. In order to perform the same tasks as in their desktop GIS, the experts need similar operations in the Cloud. They also need a way to run automated processing workflows in the Cloud.

The workflows in a desktop GIS are typically programmed in a general-purpose language (GPL) such as Python. Most GIS experts, however, do not have a background in computer science or workflow programming. In our architecture we use a Domain-Specific Language (DSL) which is tailored to the processing of geospatial data. Such a language is easier to learn than a GPL and enables GIS experts to define their own workflows without a deep knowledge of programming. Our DSL abstracts from the details of Cloud Computing and distributed programming so that the GIS experts can focus on the workflow instead of technical details.

Our system also offers a way to share workflow definitions with other users. This enables GIS experts to use pre-defined workflows in which they just need to set the location of the input datasets and modify the parameters of the processing algorithms. The DSL helps the experts to quickly understand a pre-defined workflow and to decide whether it is suitable for the envisaged task.

==== Users (Data providers)

The users of our system typically obtain geospatial datasets from companies specialising in data acquisition and preprocessing. These data providers use methods such as terrestrial or airborne laser scanning and photogrammetry to collect large amounts of raw input data. In order to produce high-quality datasets that can be used in practical applications, the input data needs to be processed and finally be converted to standardised file formats.

For this purpose, data providers require an infrastructure that allows them to specify automated processing workflows for large data sets. They have similar requirements as the GIS experts but use different spatial operations or algorithms. They also operate on much larger datasets that are often produced in a short amount of time and that need to be processed and made available to customers quickly.

The people working at data provider companies are often also GIS experts and have a similar background. They also want to use existing pre-defined workflows for automated tasks in order to save time. However, since they need to deal with varying conditions (due to new acquisition methods and hardware) as well as changing requirements from their customers, they also need to be able to adapt processing workflows. Our Domain-Specific Language helps these people to understand pre-defined workflows and to write their own if required.

==== Members of the system development team

The system development team consists of software analysts, designers, architects and developers. Their main responsibility is system development and implementation. They aim to create a system with a maintainable and extensible structure and code base. They wish to assign clear responsibilities to components (_high cohesion_) and to keep the number of dependencies between components low (_loose coupling_).

The microservice architectural style helps the members of the system development team to implement components (i.e. services) that serve a specific purpose and that have a well-defined and stable interface to communicate with other components. This allows them to easily add new features to the system and to deliver them quickly to customers. With the smaller code-base of the individual microservices they can also fix bugs faster.

==== Developers of spatial processing algorithms

Besides the system development team that is responsible for the processing platform--i.e. the user interface and the components dealing with workflow and data management--there are other software developers who contribute individual spatial processing algorithms. These people are often experts in mathematics, physics, photogrammetry, geomatics, geoinformatics, or related sciences, but have no background in computer science and hence limited knowledge of programming of distributed applications. They developed algorithms in the past for other projects and now want to leverage the Cloud to process large geospatial datasets. To this end, they wish to integrate their algorithms in our architecture--i.e. to register them as _processing services_ (see Section <<sec:architecture-processing-services>>).

The services have very diverse interfaces and are implemented using various programming languages and for different platforms. Since the services are used in multiple projects, the developers seek a way to easily integrate them into our system without modification. Our lightweight service metadata specification (see Section <<sec:processing-service-metadata>>) enables them to do so.

Most of the services are single-threaded and do not harness the capabilities of multi-core systems or distributed computing. Our JobManager can distribute these services to multiple compute nodes in the Cloud. This allows the service developers to parallelise their algorithms without changing their code.

The developers typically work for different companies and institutions that are distributed across many countries. The microservice architectural style enables distributed teams to work on multiple components at the same time and to contribute them to a single integrated system.

==== Integrators

Integrators are people who take the spatial processing algorithms as well as the different software components created by the system development team and integrate them according to our architecture. To this end, they require the following:

* A repository of software components to integrate (artefacts). The repository should be able to store metadata for each artefact including a unique component identifier, a version number, and information about how to contact the developers. Ideally, the repository should also offer a versioning system so that the integrators can always access all versions of each service.
* Components with well-defined interfaces that can be integrated without manually creating additional middleware components, converters, or wrappers.
* Well-defined interface descriptions for processing services with arbitrary interfaces.

The microservice architectural style has benefits for the integrators because the individual services are isolated. They have a high cohesion and a low number of dependencies. In addition, in contrast to a monolithic system, the services can be integrated and deployed separately.

==== Testers

Before going into production, the system needs to be tested in order to identify missing functionalities and to avoid bugs. This applies to the individual services as well as the integrated system.

The microservice architectural style allows the services to be tested separately. Interface descriptions define how the services can be called, what input data they accept and what output data they produce. After the components have been put together, additional integration tests can be performed to check the system's behaviour.

While the system is evolving, updates to individual system components can happen very often. Testing efforts increase with the number of components and the complexity of the microservice architecture. Since manual testing can be very time-consuming, testers try to automate recurring tasks. This requires the service interface descriptions to be machine-readable. It also requires a repository from which executable artefacts can be obtained and deployed in an automated manner.

==== IT operations

Among other things, people from the IT operations group are responsible for deploying the integrated system into production, as well as configuring, maintaining, and monitoring the infrastructure.

The system deployment should be easy and fast, so that new features and updated components can be delivered in a short time. To this end, IT operations people try to leverage automation and write deployment scripts for tools such as Ansible, Chef, and Puppet. Container-based virtualisation (e.g. with Docker) allows operations people to quickly start and stop services without having to take care of software dependencies and platform requirements.

In our architecture, processing services can be put into Docker images. The JobManager is able to automatically run such services on compute nodes in the Cloud without requiring the IT operations group to explicitly install them.

IT operations are also responsible for keeping the system online without interruptions. The microservice architectural style allows them to deploy updates of individual services without restarting the whole system. It also enables Continuous Delivery strategies such as _Blue-Green Deployments_ or _Canary Releases_ which allow for _Zero-Downtime Releases_ with the possibility to roll back faulty deployments to stable versions cite:Humble2010[]. Software components should be stored in a binary repository with a version control mechanism, so that older versions can be accessed and deployed quickly and in an automated manner.

In order to guarantee the smooth operation of our system, IT operations also need comprehensive logging and monitoring facilities at a centralised location. They need to be able to check the status of individual components as well as the system as a whole, and to identify operational issues such as the occurrence of an unusual number of errors, uncommon memory usage, or unexpected load peaks.

The IT operations people are also administrators who need to adapt the system _a)_ to a specific infrastructure and _b)_ to a certain application, domain, or use-case. The system should therefore be configurable. It should be possible to change its behaviour without modifying and recompiling the code. In our architecture we use a rule-based system whose production rules can be modified dynamically during runtime if necessary.

==== Business professionals

There are a number of people who have in interest in our system because they want to do business with it. For example, companies can act as resellers and offer our system to interested customers from the GIS community. These companies may provide additional products such as data and processing algorithms, or services such as the definition of pre-defined workflows. They also might want to add new software components to extend the system and to adapt it to the requirements of their customers.

In addition, there are business professionals working at data provider companies who want to offer high-quality data products to their customers and to keep costs low. These people want to make use of the Cloud in order to avoid having to maintain on-premise hardware. They also prefer a high degree of automation, so that data can be processed with minimal human interaction and hence minimal costs.

Managers of GIS projects have requirements similar to those of data provider companies. They need to carry out projects without exceeding their budgets. To summarise, business professionals require a system that has the following capabilities:

* The system should produce high quality results in a short amount of time.
* The system should be highly automatable and require minimal human interaction.
* Maintenance costs should be low. It should be easy to integrate new software components and processing algorithms in the system and to further develop them separately without having to take insight in the rest of the system.
* Costs for operation should be low. This means it should be possible to use Cloud resources instead of on-premise hardware, which would require additional maintenance efforts.
* Business professionals require a short time to market. Software extensions as well as produced data should be made available to customers as fast as possible in order to keep up with or outperform competitors.

Our system supports these requirements due to its microservice architecture, which facilitates modularity, extensibility, low maintenance costs, and a short time to market. In addition, our system has a workflow management component that allows recurring processes to be completely automated.

[[sec:architecture-quality-attributes]]
=== Quality attributes

In the previous section we defined stakeholders and their requirements towards our system. Based on this, we can now derive a list of quality attributes that our system should have. According to citet:Bass2012[locator=63] a _quality attribute_ is a "`measurable or testable property of a system that is used to indicate how well the system satisfies the needs of its stakeholders.`"

A common way of describing a quality attribute is by specifying a general scenario under which it becomes evident. A general scenario describes some kind of a stimulus (an event) and how the system responds to it. The scenario also includes evaluation criteria (measurable to testable) that can be used to validate if the system actually satisfies the needs of the stakeholders.

A scenario description consists of the following parts:

1. *Source of stimulus.* The actor or the system component that triggers the stimulus.

2. *Stimulus.* An event that requires a response from the system.

3. *Environment.* The circumstances under which the stimulus occurs (e.g. the state the system is in when the stimulus arrives).

4. *Artefacts.* The system components affected by the stimulus (often this is the whole system).

5. *Response.* The way the system responds to the stimulus.

6. *Response measure.* Evaluation criteria used to validate if the system responds to the stimulus as expected or required by the stakeholders.

In the following we provide a list of quality attributes our system should have. We also specify a general scenario for each attribute. In Chapter <<chap:evaluation>> we will utilise the general scenarios to derive concrete ones and to evaluate our system under practical conditions.

==== Performance

One of the main quality attributes our system should have is a good _performance_. In Section <<sec:introduction-use-cases>> we presented a use case dealing with urban data that needs to be processed at least as fast as it was acquired. This means there is a time limit (or a deadline) for our system to finish the data processing--i.e. to completely execute the processing workflow. In order to satisfy requirements like this, our system should make best use of available computational resources. One way to achieve this is to distribute processing tasks to compute nodes in the Cloud in a way that available CPU power is used effectively and the amount of data transferred over the network is minimised.

The architecture presented in this chapter includes a JobManager that is able to run geospatial processes (or _processing services_) in parallel on multiple Cloud nodes. The JobManager contains a configurable rule system that can be used to add constraints for the JobManager's task scheduler and to make it leverage data locality by executing individual calls to processing services on those nodes that contain the data to be processed. In other words, the processing services are transferred to the data and not the other way around. This reduces the amount of data copied over the network and hence improves performance.

Table <<tab:architecture-quality-attribute-performance>> describes a general scenario for the performance quality attribute.

[[tab:architecture-quality-attribute-performance]]
.Performance General Scenario
[cols="8,42a",frame=topbot,grid=none]
|===
| *Source*
| Users, GIS experts, data providers

| *Stimulus*
| Execution of a workflow

| *Environment*
| Normal operation

| *Artefacts*
| Components for workflow management--i.e. JobManager (Section <<sec:architecture-jobmanager>>) and processing services (Section <<sec:architecture-processing-services>>)&mdash;as well as the data storage system (Section&nbsp;<<sec:architecture-data-storage>>) and the network.

| *Response*
| The system executes the workflow and offers the processing results for download

| *Response measure*
|
_1)_ The workflow was executed in a given amount of time

_2)_ The system utilised available computational resources as good as possible

_2.1)_ All compute nodes were used to their full capacity (CPU power)

_2.2)_ The amount of data transferred over the network is minimised

|===

==== Scalability

According to citet:Bondi2000[] the term _scalability_ means that a system should be able to "`accommodate an increasing number of elements or objects, to process growing volumes of work gracefully, and/or to be susceptible to enlargement`". In our case this means that our system should be able to handle the following aspects:

* An increasing number of users and concurrent workflow executions
* Processing of arbitrary data volumes
* Changes to the infrastructure such as an increasing number of compute nodes

The system should perform equally well under all conditions. It should not fail under heavy load (multiple workflow executions at the same time, or huge amounts of data to process) and it should make use of available Cloud resources as good as possible. For example, if new compute nodes are added the system should be able to make use of their CPU power and execute workflows in a shorter time.

Table <<tab:architecture-quality-attribute-scalability>> summarises the quality attribute in a general scenario description.

[[tab:architecture-quality-attribute-scalability]]
.Scalability General Scenario
[cols="8,42a",frame=topbot,grid=none]
|===
| *Source*
| Users, data, developers, infrastructure

| *Stimulus*
| The number of a certain element increases or the volume of work grows

| *Environment*
| Normal operation, overloaded operation

| *Artefacts*
| Whole system

| *Response*
| The system continues to work

| *Response measure*
| 1) The system does not malfunction under heavy load (multiple workflow executions at the same time)

2) The system should be able to process workflows faster the more computational resources are available

3) The system is able to process arbitrary data volumes without failing or becoming excessively or irregularly slow

|===

==== Availability

Our architecture executes workflows by running a high number of processing services in a distributed environment. A single workflow execution can take a long time and the users expect the system to reliably provide processing results after the workflow has finished. However, in a distributed environment there are many things that can go wrong cite:Nygard2007[]. For example, the communication between distributed microservices can be interrupted because of a network failure, a single service can crash because of a software bug, or a whole set of services can become unavailable because a virtual machine goes offline. Under such circumstances our system should still be able to continue operating, to execute workflows and to process data. If a workflow execution is interrupted the system should be able to resume as soon as normal operation has been restored, or to repeat or reschedule work of failed compute nodes elsewhere.

The components of our system are designed to be redundant, so there is no single point of failure (SPOF). For example, the main component of our system, the JobManager, can be run in a clustered configuration. The distributed file system we use for data storage offers a high fault tolerance with respect to hardware errors through data replication.

[[tab:architecture-quality-attribute-availability]]
.Availability General Scenario
[cols="8,42a",frame=topbot,grid=none]
|===
| *Source*
| Hardware, software, physical infrastructure

| *Stimulus*
| Crashes, lost messages, incorrect responses, timeouts, etc.

| *Environment*
| Any mode of operation

| *Artefacts*
| Whole system, virtual machines, physical infrastructure

| *Response*
| The system should prevent faults from becoming a failure. It should continue to work in a degraded mode and try to recover from it as soon as possible.

| *Response measure*
| 1) The system should be still able to finish workflow execution, even if there is a fault

2) The workflow execution might take longer as usual but should produce the same results.

|===

==== Modifiability

Our stakeholders require our system to be modifiable at least at the following levels:

1. The users want to control how our system processes data

2. The members of the system development team want to add new features

3. Developers of geospatial algorithms want to integrate their processing services into our system

As we will show later, our system offers a way to specify processing workflows in a Domain-Specific Language. This allows users to control the behaviour of our system in terms of what data it selects and which processing services it applies to it in what order.

Our architecture is based on microservices. Services can be interchanged and connected in different ways. The independence of individual components allows the architecture to be modified later without requiring a specific service implementation to be changed. Similarly, new services and hence new functionality may be added without modifying the rest of the system. This applies to both core services and processing services.

[[tab:architecture-quality-attribute-modifiability]]
.Modifiability General Scenario
[cols="8,42a",frame=topbot,grid=none]
|===
| *Source*
| Users, system developers, processing service developers, integrators

| *Stimulus*
| Add, remove or modify functionality or services. Change technologies, modify configurations, etc.

| *Environment*
| Compile time, build time, runtime

| *Artefacts*
| Code, interfaces, configurations, data, etc.

| *Response*
| The modification is made and deployed

| *Response measure*
| It should be possible to make modifications without having to rebuild and redeploy the whole system

|===

==== Development distributability

As mentioned in Section <<sec:architecture-stakeholders>> developers who want to contribute processing services to our system often work for different institutions distributed across many countries. Similarly, the members of the system development team can also be located in various places.

Our architecture should therefore support distributed software development. As described in Section <<sec:architecture-microservice-architectures>> the microservice architectural style allows multiple teams to work concurrently on different aspects of the same system. Each team is responsible for one or more microservices. Since the dependencies between the services are kept at a minimum, the development can happen almost independently. The processing services that can be integrated in our system typically do not even have any dependency to any other service in our system.

[[tab:architecture-quality-attribute-development-distributability]]
.Development Distributability General Scenario
[cols="8,42a",frame=topbot,grid=none]
|===
| *Source*
| Developers, integrators

| *Stimulus*
| Develop system components in distributed teams

| *Environment*
| &ndash;

| *Artefacts*
| Processing services, core system services

| *Response*
| Developed and integrated software components form a system

| *Response measure*
| Independent and distributed teams can develop software components and integrate them into the system on their own
|===

==== Deployability

In order to put our system into production, it has to be deployed to a Cloud environment. Since a full deployment can consist of a large number of microservices that need to be distributed to multiple nodes, the deployment can be very complex and take a long time.

In order to reduce manual efforts and to make the whole process reproducible, the deployment should be automated as much as possible. In Section <<sec:evaluation-deployability>> we will evaluate the deployability of our system and will show that IT automation tools such as Ansible cite:ansible2017[] can be used to deploy and update the complete system with only one command. In addition, our JobManager is able to deploy containerised processing services on demand using Docker, even without special IT automation scripts (see Section <<sec:architecture-automatic-service-updates>>).

[[tab:architecture-quality-attribute-deployability]]
.Deployability General Scenario
[cols="8,42a",frame=topbot,grid=none]
|===
| *Source*
| System developers, processing service developers, integrators, IT operations

| *Stimulus*
| Deploy the whole system, update single services, or change configuration

| *Environment*
| Initial deployment, normal operation

| *Artefacts*
| Whole system, individual services, configuration

| *Response*
| The system is fully operational

| *Response measure*
| 1) The deployment process is fully automated

2) All services are up and running

3) The modified configuration is in effect

|===

==== Portability

Another important quality attribute of our architecture is portability. The architecture is designed to run on various Cloud infrastructures. It does not require a specific hardware nor does it require a specific Cloud infrastructure provider such as AWS, Google Cloud Platform or Microsoft Azure. The same applies to the operating system, although we primarily tested our implementation on Linux. The core services of our system are implemented in Java and should run on Windows or other platforms as well. The majority of the processing services is containerised using Docker, which runs on various operating systems.

The only requirement is that there has to be at least one computer where we can deploy our services and perform the data processing. Whether this computer is a virtual or a physical machine is irrelevant for our architecture. Although we specifically designed it for Cloud environments our system also runs on a workstation, a Grid or a Cluster.

Portability is not only important to improve the usability of our system (in particular for IT operations) but also helps exploiting it commercially. Our system does not bind possible customers to a specific Cloud provider.

[[tab:architecture-quality-attribute-portability]]
.Portability General Scenario
[cols="8,42a",frame=topbot,grid=none]
|===
| *Source*
| Business professionals, customers, IT operations

| *Stimulus*
| The system should be deployed to a certain environment

| *Environment*
| Initial deployment

| *Artefacts*
| Whole system

| *Response*
| The system is fully operational

| *Response measure*
| The system can be deployed to multiple platforms

|===

[[sec:architecture-other-quality-attributes]]
=== Other quality attributes

In the previous section we listed a number of quality attributes our system should have and defined scenarios which we will use later to validate that the system meets the requirements of its stakeholders (see Chapter <<chap:evaluation>>).

In this section we list other quality attributes we considered while designing the architecture. These additional attributes are, however, either of minor importance for the stakeholders or their complete specification and evaluation is beyond the scope of this work. For the sake of completeness we list them here but we do not specify validation scenarios.

==== Usability

As described above, our system should allow GIS experts to specify processing workflows without a deep knowledge of programming or Cloud Computing. We therefore designed an interface based on a Domain-Specific Language which we will present in Chapter <<chap:workflow-modelling>>. This language is intended to be easy to use.

In this work we focus on the software architecture, the data processing and the workflow modelling. In Section <<sec:dsl-user-interface>> we briefly describe a web-based editor for our Domain-Specific Language, but a description of a full user interface is not part of our work. A comprehensive study on usability is also beyond the scope of this thesis.

==== Interoperability

Our system does not directly communicate with other systems, so interoperability is not of major importance. However, the datasets that our system processes are typically generated by other systems. Similarly, the workflow results produced by our system are usually supposed to be read by other systems. We recommend using standardised file formats for geospatial input and output data. This kind of interoperability depends almost completely on the processing services and what file formats they support but not directly on our architecture. Other services in our system do not interact with geospatial datasets.

As described in Chapter <<chap:processing>> the JobManager has a rule-based system to create executable process chains from workflow definitions. With this rule-based system it is actually possible to add preprocessing and postprocessing services that convert data from one file format to another. However, this approach still depends on the file formats supported by the processing services and what conversion services are available.

In the IQmulus research project, where we created a productive system based on our design, we identified a number of file formats all processing services had to support in order to implement the use cases defined in the project. We tried to keep this number as low as possible. However, for full interoperability with other Geographic Information Systems, the services must support a wide range of file formats or there must be appropriate conversion services.

==== Testability

Testing is an essential part of software development. It allows developers, users, and integrators to validate if a system component (service), a set of components, or the system as a whole works as expected and meets the requirements of its stakeholders. Testing can significantly reduce the costs of integrating and maintaining a software component. It takes some effort during development to set up the tests, but it typically pays off later on, especially if the test coverage is high and the tests are automated.

In order to test a distributed system such as ours, testing should happen at various levels: classes, modules, interfaces, services, the system as a whole, etc. There are various strategies ranging from unit tests, end-to-end tests, and integration tests to acceptance tests.

Microservices are separate programs that should serve a specific purpose. Strategies such as unit testing and contract-driven testing can be used to validate if a single service meets its requirements and behaves as expected. However, as soon as many services need to be integrated to a larger application, testing becomes more complex.

A comprehensive description on how to test a large distributed system with a microservice architecture such as ours is beyond the scope of this work. For further information we refer to citet:newman2015[suffix=", Chapter 7"]. We also would like to refer the reader to citet:Cohn2009[] and citet:fowler2012[] who define a concept called _test pyramid_ that helps developers decide how much effort they should put into what kinds of tests.

==== Security

Geospatial data may contain sensitive information. Special care needs to be taken to secure the data when it is stored and processed in the Cloud. We investigated this topic in parallel with this thesis cite:hiemenz-kraemer-2017,kraemer-frese-2017[]. We summarise some relevant aspects in Section <<sec:architecture-security>>, but a comprehensive security concept is beyond the scope of this work.

== Architecture overview

This section introduces the overall architecture of our system. An overview of all components is depicted in Figure <<img-architecture-overview>>. The individual components are described in detail in subsequent sections.

[#img-architecture-overview.bottom]
.Overview of the software architecture
image::images/03_architecture/2017-05-26_architecture-overview.pdf[scaledwidth="94%",align="center"]

The GIS expert uses the system through a web-based user interface. This interface consists of three components: a data upload form, a data browser and a workflow editor.

First, the GIS expert uses the data upload form to store new geospatial data in the Cloud. The upload form sends the data to the data access service (Section <<sec:architecture-data-access-service>>) which saves it in a distributed file system (Section <<sec:architecture-data-storage>>). In addition, a new entry with metadata about the uploaded data is created in the data catalogue (Section <<sec:architecture-data-catalogue>>). Metadata can either be generated based on default values or it can be provided in the uploaded form--e.g. as an citet:ISO19115[] compliant XML file.

After uploading datasets, the GIS expert specifies a high-level workflow using a Domain-Specific Language (Section <<sec:architecture-workflow-editor>>). The workflow is saved in a workflow database for later use. Additionally, it can be shared with other users.

A workflow can contain placeholders for the datasets to be processed (see Chapter <<chap:workflow-modelling>>). The GIS expert has to select datasets and assign them to these placeholders. For this, the GIS expert uses the data browser, which is a user interface for the data catalogue that stores all information about data uploaded to the distributed file system. The data browser allows for searching based on a spatial extent or metadata.

The GIS expert then executes the workflow through the user interface. The workflow will first be parsed (Chapter <<chap:workflow-modelling>>), interpreted and finally processed by the JobManager (Section <<sec:architecture-jobmanager>> and Chapter <<chap:processing>>). The JobManager queries the catalogue service (Section&nbsp;<<sec:architecture-catalogues>>) for metadata about the data to be processed (data catalogue) as well as information about the available processing services (service catalogue). The service catalogue contains information specified by the processing service developers (Sections&nbsp;<<sec:architecture-processing-services>> and <<sec:processing-service-metadata>>).

After selecting the right data and processing services, the JobManager applies a pre-defined set of rules to create process chains specifying which services should be executed, in which order and on what nodes in the Cloud. The JobManager starts the services and monitors their execution while the services store their processing results in the distributed file system.

Finally, the JobManager creates a new entry for the generated result set in the data catalogue. After that, it sends a notification to the user
interface. If the process is long-running and the user has already closed
the user interface, this notification might also be an email sent to the
user's inbox.

[[sec:architecture-workflow-editor]]
== Workflow editor

In order to control geospatial processing in the Cloud, the GIS expert defines high-level workflows in a web-based workflow editor in our system's user interface. The editor is based on a Domain-Specific Language (DSL). The aim is that users should be able to quickly learn the DSL and to easily read and understand workflows written in it.

The main benefit of our DSL is that it is high-level and does not require users to know details about available processing services, the structure of the data stored in the Cloud, or the infrastructure the services are executed on. Instead, the users can focus on the workflow--i.e. on _what_ they want the system to do and not on _how_ it should be done. For example, the following workflow first selects a data set containing a recently updated point cloud. It then removes `NonStaticObjects` from the data set. `Trees` and `FacadeElements` are selected and put into another data set called `CityModel`.

[source,subs=+quotes]
----
*with* recent PointCloud *do*
    *exclude* NonStaticObjects
    *select* added Trees *and* added FacadeElements
    *update* CityModel
*end*
----

Note that terms such as `recent` or `NonStaticObjects` can mean many things depending on the context in which they are used (i.e. application domain). We use declarative knowledge encoded in rules to map such terms to processing services or processing parameters (see Section&nbsp;<<sec:dsl-code-generation>>). For more information about the workflow editor, the Domain-Specific Language, and the language design process we refer to Chapter <<chap:workflow-modelling>>.

[[sec:architecture-processing-services]]
== Processing services

As described in Section <<sec:architecture-stakeholders>> the spatial algorithms in our system are implemented by experts from various domains with different backgrounds. Each algorithm is provided as a separate program. We call these programs _processing services_. A processing service is a microservice that runs in its own process and serves a single specific purpose--i.e. it implements exactly one algorithm. For example, there is a service for corregistration, one for triangulation, one for intersecting 2D or 3D data, etc. Linking multiple processing services to a chain allows complex workflows to be created. A similar approach can be found in the Unix operating system where pipes can be used to send data through multiple programs. A workflow in our system can be compared to a Unix pipeline.

Input and output parameters of each service are described in a catalogue (see Section <<sec:architecture-catalogues>>). This allows the system to correctly connect them to executable process chains (this process is described in Chapter <<chap:processing>>). Our system supports a wide range of processing services developed using various programming languages and paradigms. This allows developers to select the best strategy to implement their services depending on the actual problem instead of the environment (i.e. our system). For example, although MapReduce is often used in Cloud Computing applications, it is not always the best solution for every problem, and other programming paradigms such as actor-based programming or in-memory computing sometimes allow for faster and more flexible algorithms. Compared to other platforms such as Apache Hadoop or Apache Spark, our system does not require algorithms to be implemented in MapReduce or a similar model. Instead, it supports arbitrary programming paradigms.

This capability of our system leads to another benefit. In the geospatial processing domain a lot of high-performance algorithms already exist and even though they might not be optimised for parallel computing it is desirable to reuse them in the Cloud instead of completely rewriting them from scratch. They can be integrated almost as-is into our system as long as they follow the guidelines described in Section <<sec:architecture-processing-service-requirements>>.

To summarise, our system supports the following types of algorithms (depicted in Figure <<img-parallel-processes>>).

[role="mt-1"]
**Single-threaded algorithms.** Our architecture allows single-threaded programs (typically existing spatial algorithms) to be executed. A service with such an algorithm runs on a single compute node and uses only one CPU core. In order to parallelise the processing, the JobManager has to distribute input data to several instances of these services.

[role="mt-1"]
**Multi-threaded/GPU algorithms.** Such algorithms run on a single node
only but make use of multiple CPU or GPU cores in order to increase performance. They typically scale vertically and profit from hardware upgrades--e.g. more CPUs, a better graphics card, or more memory. However, they do not scale horizontally over multiple nodes in the Cloud. In order to compensate for that, the JobManager distributes input data to multiple instances of such algorithms.

[role="mt-1"]
**Distributed algorithms.** Our architecture supports algorithms implemented using distributed programming paradigms such as agent-based programming or in-memory computing. Such algorithms are typically provided as binary executables. The JobManager executes them and oversees their resource usage.

[role="mt-1"]
**Batch and stream processing.** We use Apache Hadoop to execute batch processing algorithms implemented in MapReduce. Such jobs may be split up into multiple tasks which run on different nodes. The tasks communicate with each other through the distributed file system. The same applies to jobs implemented for Apache Spark or similar systems, as well as any stream processing framework.

[#img-parallel-processes.top]
.Processing services can be implemented in different ways. They communicate through a distributed file system. The JobManager executes the services in the Cloud.
image::images/03_architecture/parallel_processes.pdf[scaledwidth="50%",align="center"]

[role="mt-1"]
Note that the most common way to implement a service is the single-threaded approach. Since the JobManager is able to parallelise service executions and to distribute data, the other approaches do not offer benefits unless a service is supposed to be integrated in various environments and not only in our system. Instead, the single-threaded approach allows service developers to focus on the algorithmics and to leave the details of distributed computing up to the system.

[[sec:architecture-processing-service-requirements]]
=== Guidelines for integrating processing services

As we will show in Chapter <<chap:processing>> we do not require processing service developers to implement a specific interface in order to integrate their services into our system. In fact, one of the key contributions of our architecture is the possibility to utilise almost arbitrary processing services. In response to the requirements from the stakeholders, this particularly applies to those services and algorithms that developers have already been working on for many years or those that have been created in the context of other projects and that should now be integrated into our system.

Nevertheless, there are a few properties that a processing service should have in order to fully integrate into the concept of our architecture. These properties usually do not require fundamental modifications to existing services.

[role="mt-1"]
**Microservice architectural style.** Every processing service should be a microservice and meet the definition given in Section <<sec:architecture-microservice-architectures>>. At least it should be small, run in its own process, and serve one specific purpose.

[role="mt-1"]
**Scientific workflow tasks.** Conceptually, a processing service is a task (or a job) in a data-driven scientific workflow (see Section <<sec:processing-business-and-scientific-workflows>>). It is a program that can be called with a number of arguments (typically a command-line application). The program reads data from one or more input files, processes the data, and writes the results to one or more output files (the locations of input and output files are part of the command-line arguments). After that, the program exits. Although we use the name _processing service_ the program should not be mistaken for a continuously running web service. See Section <<sec:processing-web-services>> for a discussion on this type of services.

[role="mt-1"]
**Metadata.** Since we do not require processing services to implement a specific interface, the way how they have to be called can vary from service to service. In order to execute a certain service and to be able to generate a command-line call for it (with the correct number of parameters, the right labels, default values, etc.), our system's JobManager has to have information about the service's actual interface. Service developers should therefore provide a machine-readable interface description for each of their services. We call such an interface description _service metadata_. The service metadata model will be specified in detail in Section <<sec:processing-service-metadata>>.

[role="mt-1"]
**Exit code.** After a processing service has finished, the JobManager evaluates its exit code in order to determine if the service execution was successful or not. According to common conventions for exit codes, a processing service should return 0 (zero) upon successful execution and any number but zero in case an error has occurred (e.g. 1, 2, 128, 255, etc.). More information on error handling is given in Section <<sec:processing-process-chain-manager>>.

[role="mt-1"]
**Semantic versioning.** One of the requirements from the stakeholders is that processing services can be continuously developed further and that new service versions can be integrated into the system and deployed at any time. In order to ensure seamless and stable operation, processing services should be versioned according to the _Semantic Versioning Specification 2.0.0_ cite:prestonwerner2013[]. This specification is widely adopted and is used by many programs and software libraries. It defines strict semantics for each component of a version number. The _major_ version should be changed if incompatible API changes have been made (e.g. if the service interface has changed in an incompatible way), the _minor_ version should be changed if functionality has been added in a backwards-compatible manner, and the _patch_ version should be changed if the service has been updated (e.g. due to a bugfix) but the interface has not changed at all.

[role="mt-1"]
**No side effects.** In order to be able to deterministically generate execution plans for workflows, the JobManager has to be in full control of the whole workflow execution. The JobManager has to know what input files a service wants to read, so it can provide them to the service in a timely manner. It also has to know which output files the service creates, so that it can pass them on to subsequent services.

Services must not have side effects. This means, for example, they must not create additional files the JobManager does not know about, nor must they read files from hard-coded locations. All input and output files must be specified as command-line arguments.

[role="mt-1"]
**Stateless.** In order to guarantee that workflow executions are deterministic and reproducible, processing service should be stateless. They should only depend on input files and other parameters given on the command-line but not on any other external state.

[role="mt-1"]
**Idempotent.** The JobManager employs strategies to handle faults during workflow execution. For example, if a processing service has failed on a compute node (e.g. because the network was temporarily unavailable), the JobManager can repeat its execution on another one. Similar to the _stateless_ property, in order to guarantee deterministic and reproducible executions, processing services should be idempotent. Regardless of how many times a processing service is executed, for the same set of input files and parameters, it should always produce the same results.

[role="mt-1"]
**Containerisation.** The JobManager supports the execution of containerised processing services. A sensible technology for this is Docker cite:docker2017[]. Containerisation (or operating-system-level virtualisation) allows processing services to be put into separate environments. A container is like a lightweight virtual machine including a separate operating system and a file system. In our case, the major benefits of containerisation are a better separation of processes and independence of platform and system libraries. Processing services wrapped into containers are isolated. They cannot interfere with other services running on the same system. Containerised processes can only access directories and files in the virtual file system of the container. External directories and files must be explicitly mounted into the container when it is started. The mounting process is controlled by the JobManager which, as a consequence, can verify (to a certain degree) that the services do not have side effects and are stateless. In addition, since the services run in their own environment they can have arbitrary requirements in terms of operating system and library dependencies without getting into conflict with other services running on the same system.

[role="mt-1"]
**Artefacts.** Processing services and their service metadata should be put into artefacts (ZIP files) and uploaded into an artefact repository so that the JobManager can find and deploy them during workflow execution (see Section <<sec:architecture-artefact-repository>>).

[[sec:processing-web-services]]
=== Other external services

As described above, processing services are expected to be command-line programs. They are launched with a set of arguments, generate a certain result, and then exit. This approach excludes continuously running web services to be used as processing services.

Nevertheless, such services can be utilised through a simple _delegate service_. A delegate service is a command-line application that performs a single request to the web service on behalf of the JobManager in the following manner:

1. It reads one or more input files,
2. sends the input data to the web service,
3. waits for its response,
4. writes the response to one or more output files,
5. and finally exits.

To the JobManager the delegate service appears like a normal processing service although it forwards (or delegates) work to another service.

The same approach can be applied to other external processing facilities. For example, Apache Hadoop or Spark jobs are typically submitted through a separate command-line application. For example, Spark applications are launched through a tool called `spark-submit` which takes a JAR file containing the actual application as well as a URL to the Spark cluster as parameters. Command-line applications such as `spark-submit` can be converted to processing services by specifying suitable service metadata.

[[sec:architecture-data-storage]]
== Data storage

There are a number of possibilities how data storage can be implemented in the Cloud. In this work we focus on distributed file systems as they satisfy all of our requirements. However, for the sake of completeness, in this section we also discuss object storage and distributed databases which both offer more or less the same capabilities as distributed file systems but provide less extensive access transparency.

[[sec:architecture-distributed-file-system]]
=== Distributed file system

A distributed file system (DFS) is a virtual file system that spans over multiple nodes in the Cloud and abstracts away their heterogeneity (see Figure <<img-distributed-file-system>>). This means that the individual nodes may use different operating systems and different actual file systems, but the DFS provides a common interface for applications to access data on these nodes, without requiring them to know where the data is actually stored (i.e. on which node and in which data centre) or what operating system and actual file system is used.

[#img-distributed-file-system]
.A distributed file system spans over multiple nodes possibly located in different data centres
image::images/03_architecture/2013-06-12_distributed-file-system.pdf[scaledwidth="100%",align="center"]

A DFS typically has the following capabilities:

* It provides _location transparency_. Applications do not have to know where the data is exactly stored. In fact, in order to improve performance, the DFS can replicate data and create copies on multiple nodes. In Chapter <<chap:evaluation>> we utilise this property to save bandwidth by executing processing services on those nodes containing the files that should be read as input data. This allows us to avoid having to transfer large amounts of data over the network. Instead, we only transfer the much smaller processing services.

* A DFS provides _access transparency_. As described above, it provides a common interface for applications to access data in a consistent way, regardless of which underlying operating system and file system is used.

* It is _fault-tolerant_ since it replicates data to a configurable number of nodes. For example, if a replication factor of 3 is configured, data will not only reside on one node but be copied to two other nodes as well, so that there will be three copies. If one or even two nodes become unavailable, there will still be a third one where the data can be found.

* A DFS is _scalable_ since it can operate on a small number of nodes up to a very large number. New nodes can be added on demand and, more importantly, without any downtime. Adding new nodes typically increases available space, whereas the exact amount depends on the replication factor. Adding nodes can also increase fault-tolerance and performance of the overall system.

In our architecture, we use a distributed file system as the main data store. The DFS contains files uploaded for processing as well as workflow results. It is also used as the main communication channel between processing services. If multiple processes are called sequentially, intermediate results will be transferred through the DFS. Figure <<img-distributed-file-system-communication>> depicts an example for this process. Service A reads an input file from the distributed file system and writes processing results back to the same file system. The subsequent service B reads the results written by A from the file system and creates another output file on the DFS.

[#img-distributed-file-system-communication]
.Two processing services communicate with each other through the distributed file system
image::images/03_architecture/distributed-file-system-communication.pdf[scaledwidth="70%",align="center"]

If both services run on the same node or in the same data centre, the services will most likely operate on local files and do not communicate over the network. This is, however, handled transparently by the DFS driver (access transparency).

A distributed file system provides a consistent way for services to communicate with each other. The characteristics described above are essential for our architecture. They provide better maintainability, improved isolation, parallelisation, as well as the possibility to handle faults during workflow execution.

[role="mt-1"]
**Maintainability.** We do not require the processing services to implement a specific interface, nor do we require them to implement a network protocol to communicate with other services (including all aspects related to this such as handling connection problems, timeouts, or incorrect responses). They just have to be able to read and write files. This principle is also known from other distributed processing architectures such as MapReduce, for example, where map tasks and reduce tasks solely communicate with each other over files. Scientific workflow management systems such as Pegasus cite:Deelman2015[] or Taverna cite:Wolstencroft2013[] work similarly.

[role="mt-1"]
**Isolation.** Processing services are microservices running in their own processes. If the only way to communicate with other services is to read and write files, the processes are perfectly isolated from each other.

[role="mt-1"]
**Parallelisation.** Multiple processes can read a file at the same time without causing conflicts. This allows our system to parallelise data processing without having to implement distributed locking mechanisms. However, if multiple processes write to the same file at the same time, conflicts are very likely. Note that despite this, we do not implement write locking either. Instead, our JobManager takes care that all output file names it generates for processing service calls are unique, so that the services never write to the same file. This is also one of the reasons why the processing services must not have side effects (see Section <<sec:architecture-processing-service-requirements>>).

[role="mt-1"]
**Fault tolerance.** The improved isolation allows for implementing fault tolerance. If one of the services should fail on one compute node, its execution can easily be retried on another node. If services communicated directly over the network with each other, retrying a service would require the preceding service(s) to send all input data again. In the worst case, the whole workflow would have to be restarted.

[role="mt-1"]
The overhead of writing results to the DFS and then reading them again in a subsequent service (as opposed to transferring them directly) is compensated by these benefits. In fact, the impact on performance is rather low. Files are in our use cases almost always processed completely and sequentially (i.e. no random file access). In addition, the underlying operating system and file system provide performance optimizations such as caches and direct memory transfer if needed.

=== Object storage

Another common way to store data in the Cloud is _object storage_ where data is managed as objects as opposed to files. Object stores usually have the same properties as distributed file systems in terms of location transparency, access transparency, fault tolerance, and scalability. The main difference is that object stores are typically not mounted but accessed through an HTTP interface.

Object storage has no hierarchical structure and no way to organise objects in folders or directories like in a file system. Some object storage technologies provide workarounds to create virtual folders. For example, in AWS S3 object keys can have prefixes such as `/my/folder/` to mimic a file system hierarchy. However, S3 still has a flat structure.

The main reason why object storage is often preferred over a distributed file system is that it is typically less expensive in a Cloud environment, in particular when very large amounts of data should be stored over a longer period. In addition, it is an isolated system. This allows for separating data storage and processing, as opposed to using the same virtual machines for both.

In this work we focus on distributed file systems. However, object storage could also be integrated into our system without much effort. As we will describe in Chapter <<chap:processing>> our JobManager is able to insert preprocessing and postprocessing steps into the workflow if necessary. The JobManager could insert special services that download and upload data before and after the calls to processing services. This would keep data access transparent and allow the same processing services to be executed regardless of which storage technology is used. However, it would also introduce overhead because all data would have to be downloaded before it could be processed, and the results would have to be uploaded at the end. In addition, the local hard drives of the compute nodes would have to be large enough to keep all intermediate data.

Alternatively, the processing services could be extended to support access to object storage technologies directly. However, this would contradict one of the main benefits of our approach, namely that we do not require services to implement a specific interface.

=== Databases

While traditional relational databases are often not optimised to store a large number of big data blobs, newer NoSQL technologies provide means for that. The document-oriented database MongoDB cite:mongo2017[], for example, offers GridFS, an API for storing large files inside the database similarly to a distributed file system. GridFS is very fast and offers properties such as replication and sharding and is often used to overcome limitations of traditional file systems such as maximum number of files or directories.

Access to databases typically happens through a special driver (e.g. JDBC). Since we do not require processing services to implement special interfaces, databases do not fit into our concept. However, similarly to object storage, the JobManager could insert services into the workflow that download and upload data from and to the database. This would introduce additional overhead but provide no real benefits compared to a distributed file system or object storage.

[[sec:architecture-georocket]]
=== GeoRocket

A new technology that combines the advantages of object storage with those of databases is GeoRocket cite:georocket2017[]. GeoRocket is a high-performance data store specifically optimised for geospatial files. It stores data in a distributed storage back-end such as AWS S3, MongoDB, HDFS, or Ceph. The data is indexed using the open-source framework Elasticsearch cite:elastic2017[].

[#img-georocket-architecture.bottom]
.The software architecture of GeoRocket
image::images/03_architecture/georocket-architecture.pdf[scaledwidth="67%",align="center"]

GeoRocket has an asynchronous, reactive and scalable software architecture, which is depicted in Figure <<img-georocket-architecture>>. The import process starts in the upper left corner. Every imported file is first split into individual chunks. Depending on the input format chunks have different meanings. 3D city models stored in the CityGML format, for example, are split into `cityObjectMember` objects which are typically individual buildings or other urban objects. The data store keeps unprocessed chunks. This enables users to later retrieve the original file they put into GeoRocket without losing any information.

Attached to each chunk, there is metadata containing additional information describing the chunk. This includes tags specified by the client during the import, automatically generated attributes and geospatial-specific ones such as bounding boxes or the spatial reference system (SRS). In addition, users can set a layer path for the import allowing them to structure their data similarly to directories in a file system. Immediately after the chunks are put into the GeoRocket data store, the indexer starts working asynchronously in the background. It reads new chunks from the data store and analyses them for known patterns. It recognizes spatial coordinates, attributes and other content.

The export process starts with querying the indexer for chunks matching the criteria supplied by the client. These criteria can be specified using a flexible query language that is comparable to SQL. Matching chunks are retrieved from the data store (together with their metadata) and merged into a result file.

The main advantage of GeoRocket is that it automatically splits large geospatial data. It indexes the individual chunks and makes them accessible through a powerful query language. Compared to the other ways to store data in the Cloud, particularly the distributed file system, GeoRocket handles many aspects transparently that our architecture either requires as given (i.e. that large data sets are split into smaller parts) or has to handle itself. For example, the data catalogue we use in our architecture to store metadata on geospatial files in the Cloud (see Section <<sec:architecture-data-catalogue>>) could be completely replaced by GeoRocket. However, similar to an object store GeoRocket has an HTTP interface. If we were to use GeoRocket in our system, the processing services would have to implement this interface. Alternatively, the JobManager could insert download and upload services into the workflow but this would again introduce additional overhead.

Using GeoRocket in our architecture is beyond the scope of this thesis. Nevertheless, despite the impact on performance, we think that GeoRocket offers enough benefits that it is worthwhile investigating its use for distributed geospatial processing in future work (see also Section <<sec:conclusions-future-work>>).

[[sec:architecture-data-access-service]]
== Data access service

The data access service provides an HTTP-based interface to the distributed file system and offers operations to upload, read and delete files or directories as well as to provide file listings, set permissions etc. The service interface implements the REST (Representational State Transfer) architectural style cite:Fielding2000[] and has the following characteristics:

* It is stateless
* Every file and every directory in the distributed file system is a resource and is represented by a unique resource identifier (URI)
* Responses are cacheable
* Operations are implicit and not part of the URI
** The service uses standard HTTP methods such as GET, POST, PUT, DELETE, etc.
** It relies on content negotiation to provide different resource representations (e.g. file listings can be rendered in HTML and JSON)

In addition, the service interface is self-descriptive and uses hypermedia links as the means of state transfer. Clients can browse the file system by entering it at the root level (the service's main entry point) and then following the links. This decouples the client from the actual URI pattern and allows clients to operate on the file system on a higher level of abstraction (i.e. hypermedia semantics). It also results in a more flexible interface that can be modified in the future without breaking clients. This capability is often referred to as the HATEOAS constraint (Hypermedia As The Engine Of Application State) and is an essential part of REST cite:Burke2013[].

In order to implement high availability, several redundant instances of the data access service may run in the Cloud. Since the service itself is stateless, the instances do not have to communicate with each other. They all access the same distributed file system and therefore serve the same content.

[[sec:architecture-catalogues]]
== Catalogues

In our architecture we use two different kinds of catalogues: a _data catalogue_ to store metadata about the datasets in the distributed file system (the original ones as well as processing results), and a _service catalogue_ keeping information about the processing services.

The data catalogue contains information such as resolution, accuracy, and the completeness of a dataset. Metadata is needed to interpret and process data in a reasonable way. The JobManager makes use of data metadata for decision making as described in Chapter <<chap:processing>>. Additionally, it needs information about the processing services such as input parameters and data types to correctly execute them.

The JobManager cannot work properly if the metadata is not available. We propose to use a distributed NoSQL database such as MongoDB, which provides replication as well as automatic failover and recovery strategies. With these features the catalogues can be set up highly available and do not become a single point of failure (SPOF).

[[sec:architecture-data-catalogue]]
=== Data catalogue

The data catalogue service provides an HTTP interface to metadata on geospatial datasets stored in the distributed file system. The catalogue is designed to support metadata standards such as citet:ISO19115[] and citet:ISO19119[]. The JobManager uses information such as resolution or size to distinguish datasets which are fast to process from others which are very detailed. It also uses this kind of metadata to decide how to split and distribute datasets to different instances of one service. If necessary, the processing services may access the data catalogue too. A more detailed description of the data metadata is given in Section <<sec:processing-data-metadata>>.

[[sec:architecture-service-catalogue]]
=== Service catalogue

As described in Section <<sec:architecture-processing-service-requirements>>, developers have to provide service metadata for every processing service they want to integrate into our system. This metadata contains information about the service and how it can be executed in the infrastructure. It is stored in a JSON file next to the service binary in the service artefact (see Section <<sec:architecture-artefact-repository>>).

The service catalogue caches the contents of these files and provides access to them in a uniform way. The JobManager accesses the catalogue to get information about available services. It uses the service metadata to build executable process chains, to prepare the infrastructure, and to deploy the services to the compute nodes. A complete specification of the service metadata can be found in Section <<sec:processing-service-metadata>>.

[[sec:architecture-jobmanager]]
== JobManager

The JobManager is one of the core components in our architecture. Its main responsibility is the execution of workflows in the Cloud.

Figure <<img-workflow-execution>> shows the data flow from the workflow editor to the processing services. First, the user writes a workflow script in the Domain-Specific Language with the workflow editor. This script is then interpreted and converted to a machine-readable workflow (see Chapter <<chap:workflow-modelling>>). The JobManager then converts the workflow to one or more executable process chains (see Chapter <<chap:processing>>). Each process chain consists of one or more command-line calls to processing services. The JobManager assigns the process chains to the individual compute nodes in the Cloud and monitors their execution.

[#img-workflow-execution]
.The complete process of executing a workflow in the Cloud
image::images/03_architecture/workflow-execution.pdf[scaledwidth="100%",align="center"]

In order to convert workflows to process chains, the JobManager makes use of a rule-based system. This system contains production rules that specify different strategies how to distribute and parallelise the computation in the Cloud. The reasoning is based on different information including data metadata and service metadata. The whole workflow execution process in described in Chapter <<chap:processing>>.

== Deployment

In this section we discuss how our system can be deployed to a productive environment. We differentiate between the deployment of _processing services_ and services that are core components of our system such as the JobManager or the data access service (_system services_).

=== Continuous Delivery

The term _Continuous Delivery (CD)_ has been coined by citet:Humble2010[]. They describe a number of patterns that should be applied in modern software development to be able to continuously deploy software to production. This means that whenever a change has been made to the software or to one of its components, the change is automatically and immediately delivered to the customers. The main aims of this approach are to reduce the time to bring a feature or a bug fix to market, to strengthen the communication or interaction with the customers, and to continuously collect feedback to improve the software.

In order for CD to work properly, the deployment process has to be almost fully automated. The process should be reproducible and the amount of human interaction should be reduced in order to avoid errors. A common strategy is to create a _deployment pipeline_ that describes the way a software artefact takes from the code repository to the production environment. A deployment pipeline is typically divided into a number of stages. The most common stages that can be found in almost any deployment pipeline are as follows cite:Humble2010[prefix="see also"]:

* In the _commit stage_ the code is compiled and validated with automated unit tests and code analysis. The steps performed in this stage are also commonly known under the term _Continuous Integration_.

* The _acceptance test stage_ contains tests that validate the behaviour of the system components and whether they satisfy specified requirements.

* Some deployment pipelines contain a _manual test stage_ in which human testers verify the software and try to identify defects not caught by automated tests.

* In the _release stage_ the software is finally deployed into production.

[#img-deployment-pipeline.bottom]
.Deployment pipeline for our system with different paths for system services and processing services
image::images/03_architecture/deployment-pipeline.pdf[scaledwidth="100%",align="center"]

It is important to note that the deployment pipeline may be aborted immediately whenever one of the steps fails. This ensures developers get instant feedback about defects in their code. It also prevents broken software artefacts from being deployed into production.

Figure <<img-deployment-pipeline>> shows the deployment pipeline for our system. In our case it consists of three stages: the commit stage, the acceptance stage, and the release stage. The pipeline starts as soon as a commit is made and uploaded into a version controlled code repository.

In the commit stage we differentiate between system services and processing services. System services are compiled, tested, and deployed to an artefact repository (see Section <<sec:architecture-artefact-repository>>). The same applies to processing services although the number of unit tests and the code analysis coverage may vary depending on the individual service developers and whether they are familiar with these concepts.

In the acceptance stage the software components built in the previous stage are first downloaded from the artefact repository. They are now treated as _black boxes_ as all tests running in this stage can only access the interfaces of the components and their metadata but not their code. Again, we differentiate between system services and processing services. Defects in the service metadata of processing services can be easily detected by validating the metadata properties. Both the processing services and the system services are then tested using smoke tests. This means they are deployed to a test environment and executed at least once with pre-defined test data. The parameters for this test environment as well as the test data are stored in a version control system. Further service tests (e.g. integration tests or end-to-end tests) may be performed in this stage. This particularly applies to system services which need to communicate with other services.

In the final stage, the release stage, the software artefacts are deployed into production. Note that the transition between the acceptance stage and the release stage is completely automatic for the processing services (see Section <<sec:architecture-automatic-service-updates>>). The system services require manual interaction to trigger the release process (see Section <<sec:architecture-infrastructure-deployment>>). Similar to the acceptance stage, the configuration necessary to release the services to the production environment is under version control.

Version control plays an important role along the whole deployment pipeline. First, the source code of the services is stored in a code repository. Second, the built software binaries are stored in an artefact repository that also contains a version control mechanism. Finally, the configuration needed for the acceptance tests and the release process are also stored in a version control system. This approach ensures that every deployment is completely reproducible and changes to the system that introduce defects can be rolled back easily. For example, if a new version of a service is deployed to the production environment and proves to be defective (although it has passed all tests in the deployment pipeline) the previous version can be restored by reverting the change in the version control system and executing the deployment pipeline again.

[[sec:architecture-artefact-repository]]
=== Artefact repository

An artefact repository is a collection of software binaries and metadata. The metadata contains information about a software artefact such as its name, a human-readable description, and a version number. The repository groups artefacts with the same name but different version numbers. Once uploaded to the repository, binaries and metadata typically cannot be edited or removed--i.e. they are immutable. Due to this, an artefact repository can be compared to a version control system for binaries. Well-known products for artefact storage are JFrog Artifactory and Sonatype Nexus.

In our architecture we use an artefact repository to store system services as well as processing services and their metadata. Since most artefact repositories have a defined metadata scheme, we propose putting processing service executables and their service metadata into ZIP files and uploading them as the binary artefacts.

The artefacts are picked up by the tests in the acceptance stage of our deployment pipeline. The repository is also accessed by the JobManager in order to deploy the processing services to the compute nodes.

[[sec:architecture-infrastructure-deployment]]
=== Infrastructure deployment

As discussed above, the whole deployment process should be automated as much as possible. This also includes the configuration of the environment--e.g. specific settings in the operating system on the virtual machines in the Cloud, or required system dependencies and daemons. In the DevOps movement cite:Loukides2012[] the term _Infrastructure as Code (IaC)_ describes the process of managing the configuration of the environment in machine-readable definition files. These files are typically stored in a version control system. They can be evaluated by IT automation tools such as Ansible, Chef or Puppet which are able to apply required configuration settings, install software and services, start daemons, etc.

The fact that the definition files are kept under version control and that they can be evaluated completely automatically allows administrators to keep a history of states of the environment and to restore a certain state with just a few commands, regardless of how many virtual machines need to be configured. In order for IaC to work properly, changes to the environment should always be done through the IT automation tool and checked into the version control system. Manually editing the configuration of a virtual machine undermines the purpose of IaC.

In our architecture we use Infrastructure as Code to automate the release stage of our deployment pipeline. We keep configurations for the virtual machines running our system services and the processing services under version control. As mentioned above, the deployment pipeline for the system services pauses after the acceptance stage has passed successfully. The release stage has then to be triggered manually by starting an IT automation tool. This allows us to decide exactly when updates should be done to the overall system. Since the whole process can be triggered with only one command, it can be repeated several times a day. See Section <<sec:evaluation-deployability>> for more details.

[[sec:architecture-automatic-service-updates]]
=== Automatic service updates

In contrast to system services, processing services are deployed fully automatically to the production environment. The JobManager is able to download the service binaries from the artefact repository and distribute them to the compute nodes. In case the processing services are containerised with Docker, the artefact repository can store the images and act as a Docker registry. This is possible with the enterprise version of Artifactory, for example. If the free community edition is used the service artefact should contain a Docker build file (Dockerfile). The JobManager is able to automatically download an artefact and run its Dockerfile to create an image for the service on the compute node.

Note that the JobManager will only deploy services that are ready to be released. For this, it relies on the service catalogue (see Section <<sec:architecture-service-catalogue>>). As soon as a service has passed the acceptance stage, a new entry for the specific service version will be made in the catalogue and its metadata will be transferred.

The fact that our processing services are isolated microservices allows us to deploy them independently and to make updates to our system without any downtime. This is one of the major benefits of the microservice architectural style, compared to a monolithic system that would be unavailable for the time the whole system is re-deployed.

[[sec:architecture-operations]]
== Operations

Our system consists of a number of microservices. As mentioned earlier, in Section <<sec:evaluation-deployability>> we show that in the IQmulus project we deployed more than a hundred services to the production environment. Most of these services are started multiple times. For example, the processing connector service (see Section <<sec:processing-processing-connector>>) has to be installed on every compute node. Likewise, during a workflow run multiple processing services are spawned at the same time on the individual compute nodes. The number of running service instances at a given point in time can therefore be much larger than the total number of services.

The fact that all these services are distributed across several virtual machines can make it very hard to maintain an overview and to ensure smooth operation. In this section we discuss two operational aspects that help get an insight into the running system: monitoring and logging.

=== Monitoring

In order to be able to manage a large number of distributed services, IT operations not only need to have an overview of which service instances are currently running but also about their state, CPU usage, memory usage, etc. Maintaining an overview and monitoring the services is key, in particular when there is an issue with the system that needs to be found or if developers and administrators try to identify performance bottlenecks. Similarly, IT operations also needs to have in-depth information about the resource usage in the Cloud. For this, they have to monitor the virtual machines and collect metrics about available memory, free hard drive space, etc.

IT operations often make use of dashboards to display current metrics about the infrastructure. Viewing numbers from a single point in time is, however, typically not enough to get a clear picture about a system's behaviour. Monitoring tools therefore collect time series of data to display historical information. As citet:Nygard2007[] has noted, it is indeed possible to predict how a system will behave in the future by looking at how it did in the past. Collecting metrics over a period of time is therefore not only useful to get a system's current or earlier state, but also helps make assumptions about how it will react to future events.

Monitoring tools for distributed systems have been in use for quite some time. One of the most mature and well-known products is Nagios cite:nagios2017[]. This tool allows for collecting common system metrics such as CPU, memory, or hard drive usage. It can also be used to monitor the state of individual services--e.g. by performing health checks. Nagios only allows for _black-box monitoring_. This means it cannot collect metrics about the internal state of a distributed application. For example, it does not know about how many connections are currently in use from a service's internal database connection pool, or how many garbage collection cycles have been triggered over the last minute.

In contrast to the black-box monitoring of Nagios there is _white-box monitoring_ which describes the approach of collecting additional service-internal or application-specific metrics. One of the solutions implementing this approach is Prometheus cite:prometheus2016[]. The open-source tool runs as a separate service which frequently collects metrics from other services in the system. Besides CPU, memory and hard drive usage, common metrics recorded with this tool are the number of open HTTP connections, request latency, open file handles, but also information about the number of failures occurred. Metrics like these can be of great importance for developers and system administrators to understand what is actually happening or has happened in the system. 

[#img-grafana-screenshot.bottom]
.Screenshot of a Grafana dashboard showing metrics collected during a workflow run
image::images/03_architecture/grafana-screenshot.png[scaledwidth="80%",align="center"]

Internally, Prometheus is a time-series database. It keeps a history of metrics which can later be queried with a powerful expression language. There are tools that work on top of Prometheus and offer additional functionality. Grafana, for example, is an open-source product that can be used to create live dashboards showing collected metrics in various ways cite:grafana2017[]. For our system evaluation which we will present in Chapter <<chap:evaluation>> we used Prometheus in combination with Grafana to collect metrics about the behaviour of the JobManager, the processing services, the compute nodes, etc. in various scenarios. Figure <<img-grafana-screenshot>> shows a screenshot of a dashboard we created with these tools. More detailed figures will be presented later.

=== Logging

Another way of performing white-box monitoring is logging. In contrast to mere numerical metrics, log files may contain additional textual information and give a broader context on a certain aspect of the system. Logging is one of the oldest and well-known methods to monitor an application or a distributed system. It is also the method providing the best loose coupling. Compared to metrics collected with solutions such as Prometheus, logging does not depend on a specific product. Log files are plain text files and can be processed by any tool or framework.

In a microservice architecture with more than a hundred services distributed to several Cloud nodes, it is important to maintain an overview of all log messages. In recent time, the so-called _ELK stack_ (or _Elastic Stack_) has become the de-facto standard for distributed logging. It consists of three tools: Elasticsearch, Logstash and Kibana cite:elastic2017[]. Logstash is a service that collects, parses and transforms log messages. Most logging frameworks can be configured to push messages into Logstash. The tool sends transformed log messages to downstream services for further processing. One of these services is Elasticsearch which maintains an index of all collected messages. Elasticsearch offers a query language with which individual log entries can be found and aggregated. The query results can be displayed in Kibana. This tool offers a web-based graphical user interface that can be used to browse through log files, perform queries and create graphs.

[[sec:architecture-security]]
== Security

In order to protect the rights of owners of the geospatial data stored and processed by our system, various security issues have to be considered. As mentioned above, a comprehensive security concept is beyond the scope of this work. Nevertheless, in this section we give a brief overview of the most important aspects and how they can be addressed with our architecture.

[role="mt-1"]
**Data storage.** A typical way to protect data against unauthorised access is data encryption. As described in Section <<sec:architecture-data-storage>> we use a distributed file system as the means to store geospatial data redundantly and in a distributed manner in the Cloud. Most distributed file systems do not offer data encryption out of the box. Such a feature would have to be implemented on top of the file system as a separate layer.

Alternatively, a more sophisticated data storage solution could be used. In parallel with this thesis, we investigated approaches to secure data storage in the Cloud. We used GeoRocket as a data store (see Section&nbsp;<<sec:architecture-georocket>>) and implemented Searchable Symmetric Encryption (SSE) on top of it cite:hiemenz-kraemer-2017[]. In addition, we were able to show that geospatial data can be kept securely in an object store in a hybrid public/private Cloud environment, while still allowing the data to be processed and shared with third parties cite:kraemer-frese-2017[].

Note that in a private and trusted Cloud, data encryption typically has no benefits but imposes performance and development overhead.

[role="mt-1"]
**Data transfer.** In a distributed system, data is typically transferred between multiple nodes. Often it even has to leave a data centre and has to be copied to another one. If security is important it should be made sure that communication between distributed microservices is encrypted. Since most of our services use HTTP, this can be easily realised by enabling SSL/TLS and switching to HTTPS. In addition to the services, the distributed file system should also be configured to encrypt data transfers between Cloud nodes. Solutions such as GlusterFS or HDFS support network encryption out of the box and just need the correct configuration items to be set.

[role="mt-1"]
**Data upload and download.** The data access service (see Section <<sec:architecture-data-access-service>>) is a REST service that enables access to the data stored in the distributed file system through a
defined HTTP interface (either from a client application or through the Web Browser). Access to this service can be secured through HTTPS using SSL/TLS.

[role="mt-1"]
**Authentication.** In order to protect our system against unauthorised access, an additional authentication layer can be added. Since our system consists of many microservices we propose to use a Single Sign-On solution such as the open-source tools Keycloak and CAS (Central Authentication Service). Such an approach makes it easier to interact with the individual distributed services in our system as users have to authenticate only once at a central location. Single Sign-On systems generate tokens that can be passed from one service to another to transport user authentication information.

[role="mt-1"]
**Authorisation.** While authentication makes sure only the right people have access to the system, it does not protect individual data sets stored in the distributed file system against unauthorised access. Most distributed file systems implement a permission model similar to the one found in the UNIX operating system. Each file is associated with an owner and a group. Separate read/write permissions for each file and directory can be assigned to the owner, the group, or all other users. This allows users with the right permissions to protect their files against other users who are authenticated but not authorised to access the data.

[[sec:architecture-summary]]
== Summary

In this chapter we presented our architecture for the processing of large geospatial data in the Cloud. We discussed relevant background and related work. After that, we performed a requirements analysis and formulated quality attributes. We then presented details on the individual components of our architecture. We also discussed deployment, operations and security.

One of the main goals of our architecture is to provide GIS users and developers with access to the Cloud. Our approach to achieve this goal is based on the microservice architectural style. Compared to a monolithic application, a microservice architecture is more modular, maintainable and extensible. In our case, developers and researchers from the geospatial community can contribute processing services and extend the overall functionality of our system. There are only minimal requirements that the processing services need to satisfy. Existing algorithms can be reused in our system without fundamental modifications. Since our workflow management component, the JobManager, is able to automatically deploy processing services to compute nodes and to parallelise their execution, our architecture even allows developers and researchers who do not have an IT background or knowledge of distributed programming to leverage the possibilities of Cloud Computing.

Due to the modularity and extensibility of our architecture, a broad range of processing services can be integrated in order to create a Cloud-based system that covers a functionality similar to a desktop GIS. With the workflow editor based on a Domain-Specific Language users can automate recurring tasks and harness the capabilities of the Cloud in terms of storage and computational power. In the following two chapters we follow up on this and discuss workflow-based data processing as well as workflow definition in detail.
