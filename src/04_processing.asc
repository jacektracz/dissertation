[[chap:processing]]
= Processing

The focus of the previous chapter was on the overall software architecture of our system for the processing of large geospatial data. We described requirements and system parameters and introduced the individual components.

In this chapter we focus on distributed data processing and workflow management. The main contributions are in the way we integrate and orchestrate services based on lightweight service metadata. In terms of workflow management we contribute to the state of the art by presenting an approach to dynamic workflow execution that does not rely on a priori design-time knowledge (compared to existing workflow management systems that require all parameters to be known in advance). This approach is based on configurable rules that select processing services and datasets, and generate executable process chains leveraging data locality.

The chapter is structured as follows. We first introduce the JobManager service which is in our architecture responsible for workflow management. We describe requirements it has to meet and compare it to related work. After that, we focus on the JobManager's software architecture. We describe the individual components within the service, as well as the control-flow between them and their interfaces. We also cover aspects such as fault-tolerance, elasticity and scalability. Finally, we evaluate the JobManager's functionality against a number of patterns often found in Workflow Management Systems. The chapter concludes with a summary.

== Introduction

A Geographic Information System (GIS) typically offers a range of spatial operations such as creating intersections and unions, buffering, or more advanced features like co-registration or data fusion. Users working with a desktop GIS, for example, usually import some data into the system, apply one or more spatial operations and save the modified result back to their hard drive or a database. Since large geospatial datasets often consist of many files that should be modified or processed in a similar way, Geographic Information Systems offer ways to automate work. For example, the open-source software QGIS has a Python API that can be used to create scripts that can be applied to a number of files in a batch. This can help GIS users to save a lot of time.

The approach of automating recurring tasks is well-known in computer science and has a long history cite:Ludaescher2009[]. A Workflow Management System is a software that allows for modelling business or scientific processes (or workflows). Such a system typically also offers a way to automatically execute modelled workflows. A workflow is a chain of activities. In the case of scientific workflows (see Section <<sec:processing-business-and-scientific-workflows>>) an activity is a processing step that is applied to input data and produces output data.

A GIS with scripting and batch-processing facilities can therefore be compared to a simple Workflow Management System. However, the more often users have to process data and the larger the datasets become, the more important it is to fully automate processing workflows and to avoid human interaction. In addition, desktop-based Geographic Information Systems run on a single computer and do not leverage the possibilities of distributed computing.

In this chapter we present a component called JobManager which can automatically execute geospatial processing workflows in a distributed environment. Together with the Domain-Specific Language we will present in Chapter <<chap:workflow-modelling>>, the JobManager forms a Workflow Management System. In order to execute the workflows, we leverage the Cloud.

Many Workflow Management Systems are suitable for a certain kind of use case or application domain. This limits their use, as they cannot be applied to problems outside the targeted application domains. They also often have very specific requirements towards the environment they run in, the infrastructure they can be deployed to, as well as the data they can handle (see Section <<sec:processing-workflow-management-systems>>). Our JobManager, on the other hand, is designed to be more flexible. We employ a production rule system (or rule-based system, or expert system) which allows us to configure the workflow execution and to adapt it to various needs and conditions. This allows us to apply our workflow management component to many use cases and to deploy it to various infrastructures (see Chapter <<chap:evaluation>>).

Since geospatial datasets can become very large and complex, the processing workflows can take a long time, ranging from a couple of hours to several days or weeks. If the process is interrupted--e.g. due to a system failure--it is important that it can be resumed without information loss and without the need to repeat work that has already been done. This is particularly important in a distributed environment where failures are expected to happen cite:robbins2012[]. We therefore designed the JobManager to be resilient and fault-tolerant (see Section <<sec:processing-fault-tolerance>>).

The fact that geospatial data sets can be large and complex also requires a scalable system. We designed the JobManager to be able to handle arbitrarily large datasets. It utilises available Cloud resources but can also scale out dynamically if necessary (see Section <<sec:processing-elasticity>>).

== Background

Before we compare the JobManager to related work and describe its components in detail, we clarify what kind of Workflow Management System it actually represents. We also introduce patterns that are often found in Workflow Management Systems. We will later make use of these patterns to compare our approach to related work and to qualitatively evaluate it in terms of functionality and capabilities.

[[sec:processing-business-and-scientific-workflows]]
=== Business workflows and scientific workflows

Workflow Management Systems have a long history in computer science. They have been used for many use cases ranging from simple office automation to complex tasks such as the modelling of business transactions or even genome sequencing. A distinction is made between Workflow Management Systems for business modelling (_Business Workflow Systems_) and those that are used to process information in a scientific context (_Scientific Workflow Systems_). There is an overlap between these two kinds of systems, but one can summarize the major differences as follows cite:Ludaescher2009[prefix="see also"]:

* Business workflows model processes in a company and often involve humans, whereas scientific workflows are typically completely automated and executed without any human interaction.
* While business workflows model the flow of control between actors (e.g. humans, departments or--if the workflows are automated--web services), scientific workflows represent the flow of data (e.g. how a specific data entity is passed from one workflow task to another through output and input interfaces).
* The outcome of business workflows is typically known at the time of modelling. The main goal is to provide a better understanding of the process for all involved parties. Scientific workflows, on the other hand, are more experimental. They start with a given set of information (or a hypothesis) and produce a result. What the result actually is can only be determined by running the workflow.
* In business workflows there can be many independent tasks and activities happening at the same time. This helps model the complex ecosystem of an organisation. Scientific workflows, on the other hand, are typically a set of tasks that are connected to a directed graph or a process chain where data flows or streams from the beginning (the first task) to the end (the last task in the chain).

In this work we focus on data-driven scientific workflows as they match our use cases and requirements better than business workflows.

[[sec:processing-workflow-patterns]]
=== Workflow patterns

In order to be able to assess existing Workflow Management Systems, one has to compare their features and the different kinds of workflows they support. For lack of a "`universal organisational theory`" that could be used for this purpose, citea:Aalst2003[] investigated various Workflow Management Systems over the course of 15 years and collected a number of what they call _workflow patterns_ cite:Aalst2003,Russell2004,Russell2004a,Russell2006,Russell2016[]. We will use these patterns in Section <<sec:processing-workflow-management-systems>> to compare our work to other Workflow Management Systems. In addition, in Section <<sec:processing-supported-workflow-patterns>> we describe which patterns our system supports and how we implement them. There are three kinds of workflow patterns:

* _Control-flow patterns_ describe the features a Workflow Management System offers to define the sequence in which individual actions in a workflow are executed.

* Workflow _resource patterns_ relate to the way a system makes use of available resources to execute tasks. In our case, this means these patterns describe how the individual tasks in a workflow are assigned to compute nodes in the Cloud and how their execution is triggered.

* _Data patterns_ deal with data access and transfer.

Whenever we refer to those patterns we use the same naming as in the original work. _Control-flow patterns_ start with the prefix _WCP-_ cite:Aalst2003,Russell2006[]. Workflow _resource patterns_ start with _R-_ cite:Russell2004[]. _Data patterns_ are only numbered in the original work cite:Russell2004a[] and do not have a prefix. In order to differentiate them from the other ones, we use the prefix _D-_.

For detailed descriptions and a complete list of workflow patterns, we refer to the work of citet:Russell2016[]. However, a set of patterns that is notable and relevant to our work is WCP-12 to WCP-15. These patterns relate to the capability of a Workflow Management System to run multiple instances of an activity depending on certain a priori knowledge. _WCP-12 (Multiple Instances without Synchronization)_ describes the general capability of running multiple instances of an activity in parallel. Systems that implement pattern _WCP-13 (Multiple Instances with a priori Design-Time Knowledge)_ are able to create multiple instances whereas it is already known at design time--i.e. when the workflow is defined--how many instances should be created. _WCP-14 (Multiple Instances with a priori Run-Time Knowledge)_ describes systems that can create multiple instances of an activity even if the number of instances is only known during run-time of the workflow--e.g. if it depends on the result of a previous activity. Systems supporting _WCP-15 (Multiple instances without a priori run-time knowledge)_ are able to adapt the number of instances while the activity is running. This means they allow new instances of an activity to be created even when some instances are already being executed or have completed.

It is important to note that while it is relatively straightforward to implement WCP-13 with a priori design-time knowledge, depending on the actual implementation it can be very hard to synchronise results of multiple instances of an activity if WCP-14 or WCP-15 should be implemented. Many Workflow Management Systems therefore do not support multiple instances without a priori design-time knowledge cite:Aalst2003[]. The system we present in this chapter, on the other hand, supports multiple instances with a priori Run-Time Knowledge (_WCP-14_) and can therefore be applied to a wider range of use cases.

[[sec:processing-related-work]]
== Related work

In this section we put our approach in the context of related work. The JobManager executes and monitors user-defined workflows in the Cloud. It can be compared to a Workflow Management System. We list some of these systems supporting scientific workflows in a distributed environment in Section <<sec:processing-workflow-management-systems>> and compare them to our approach. The JobManager's Rule System evaluates workflows and generates executable process chains. For this, it has to orchestrate processing services with different interfaces. We discuss service and component orchestration in Section <<sec:processing-service-orchestration>>.

[[sec:processing-workflow-management-systems]]
=== Workflow Management Systems

There are a lot of Workflow Management Systems covering a wide range of use cases cite:Sheth1999[]. In this section we specifically focus on those supporting scientific workflows and operating in a distributed environment (i.e. a Cloud, Grid or Cluster).

One of the most popular Workflow Management Systems targeting science applications is Apache Taverna cite:Wolstencroft2013[]. The open-source system has been used in production for many years. It specifically targets use cases from the area of bioinformatics but can also be used in other related domains. Taverna has a graphical workflow editor that runs as a desktop application. Once a workflow has been modelled, it can be executed either locally or on a Grid, Cluster or Cloud infrastructure. The system supports various service types. It can execute web services that offer a WSDL interface cite:wsdl2001[], REST services, bean shell scripts and others. It also supports executing command-line applications (or _tools_), for which users have to specify input and output ports. This is in contrast to our approach where the interface of a service is described by the service developer and not by the user.

The data items passed from one task in a Taverna workflow to another are either primitive values or lists (workflow data patterns _D-9_ and _D-27_ to _D-31_). Command-line tools read their input from the command line or from files and write results to the standard output stream or a new file. Taverna does not support exclusive choices (workflow control-flow pattern _WCP-4_) or arbitrary cycles (_WCP-10_). However, it supports structured loops (_WCP-21_) with post-conditions. This is typically used to repeatedly call a web service until it returns a certain result.

The possibility to specify multiple instances of a workflow task without a priori design-time knowledge (_WCP-13_ and _WCP-14_) is limited in Taverna. The system has a notion of _implicit iterations_. If task A produces a list but a subsequent task B expects a single value as input, B will automatically be executed multiple times for each list item. This works for web services and beanshell scripts, but not for command-line tools that write to the standard output stream or to a single file. The processing services we use in this work can write results to multiple files in a directory. Our JobManager supports iterating over the files in this directory and calling subsequent services for each of them. In Taverna such a use case is only possible with a workaround. A service can be wrapped by another one that writes the absolute path of the directory containing the results to a separate file. A subsequent task can then list the contents of this directory and output a list of files. Through the implicit iteration mechanism, multiple task instances can then be applied to the items on this list.

This approach makes the workflow unnecessarily complex. For geospatial applications where this case happens rather often (e.g. see the description of the workflow of our use case B in Section&nbsp;<<sec:evaluation-use-case-b>>) the workaround is impractical. In addition, the fact that the wrapper service has to write an absolute path to a file, binds the workflow to a certain execution environment--i.e. one that has a local file system. In general, Taverna does not focus very much on issues of portability. Workflows that have been designed for a certain platform can often not be transferred to other environments easily without changing the tasks or the executed services.

Another Workflow Management System that specifically aims for platform-independent scientific workflows is Pegasus cite:Deelman2015[]. Just like Taverna, Pegasus is open-source and has been under constant development for many years. Its origins are in bioinformatics, but Pegasus has been used for many other use cases from various domains. The system supports executing workflow tasks on various platforms including Grids, HPC clusters, and the Cloud. It relies on HTCondor which is a mature system for high-throughput computing on distributed platforms cite:Thain2005[]. The system handles issues of portability by abstracting datasets, workflow tasks and execution sites from the actual files, processing services and runtime environments respectively. Pegasus has a replica catalogue containing information on how to look up files, a transformation catalogue specifying how a workflow task should be executed, and a site catalogue containing information about the computational and storage resources. This is very similar to the service metadata and data metadata in our JobManager (see Sections <<sec:processing-service-metadata>> and <<sec:processing-data-metadata>>).

Workflows in Pegasus are Directed Acyclic Graphs (DAGs). The main exchange format for workflows is XML. As the name implies, Pegasus DAGs must not contain cycles (_WCP-10_). There are no conditions (_WCP-4_) and therefore no structured cycles (_WCP-21_). However, Pegasus compensates this drawback by offering an API for popular general-purpose programming languages including Python and Java. The API provides a means to generate DAG XML files on a high-level. Since the general-purpose languages have loops and conditional expressions, complex workflows can still be created. However, the whole workflow structure must be known at design time (_WCP-13_). The possibility to determine the number of instances of a workflow task at runtime (_WCP-14_) is not directly possible. Instead, one has to create a task that generates a new DAG XML file for a subworkflow, plus another task that submits the new subworkflow to the system's scheduler. This is one of the major differences between Pegasus and our JobManager.

Another difference is in the way both systems handle files and computational resources. The workflow tasks in both Pegasus and the JobManager communicate with each other by reading input from files and writing results to new files (_D-29_). In Pegasus these files can either be located on a distributed file system, an object store such as AWS S3, or other storage systems. Pegasus is able to automatically handle various storage types and provide a transparent way for the workflow tasks to access the data. The resource management features are directly integrated into Pegasus. The JobManager, on the other hand, is more lightweight and distributes work to other microservices. For example, if a certain processing service is not able to read a file from a distributed file system or from an object store, the JobManager's Rule System (see Section <<sec:processing-rule-system>>) can insert an additional service into the workflow that downloads the requested file to the local file system, and another one that later uploads the processing results back to the data store.

Both systems support allocating computational resources based on algorithms such as Random Allocation (workflow resource pattern _R-RMA_) or Round-robin Allocation (_R-RRA_). The JobManager additionally supports allocating based on capabilities (_R-CBA_) and shortest queue (_R-SHQ_) while Pegasus supports the HEFT algorithm which prioritises tasks and selects processors which minimise their finish time cite:Topcuouglu2002[]. In order to leverage data locality--i.e. to reduce the amount of data that needs to be transferred between two jobs and to optimize the workflow's execution time--the JobManager can execute multiple workflow tasks on the same computational resource. The JobManager's Rule System generates process chains which are a set of processing services executed on the same virtual machine. This capability is described in workflow resource patterns _R-RF_ and _R-CE_. In Pegasus workflow tasks can be grouped to be executed on the same site. Pegasus also offers a way to cluster tasks, although this feature is typically only used for short-lived tasks to reduce the latency introduced by the HTCondor scheduler.

citet:gil2011[] describe an extension to Pegasus, which is called WINGS. This extension allows users to design semantic workflows that are independent of the technical details of their execution. WINGS contains a rule-based semantic reasoner that is able to transform a semantic workflow to a concrete one by selecting matching data sources and workflow task instances. This approach is similar to ours, since we also propose a technology-independent way (i.e. our Domain-Specific Language described in Chapter <<chap:workflow-modelling>>) to define an abstract workflow (see Section&nbsp;<<sec:processing-workflow>>), which is translated to executable process chains by a rule-based system (see Section&nbsp;<<sec:processing-rule-system>>). However, the semantic reasoner in WINGS makes use of ontologies and requires all datasets and task instances to be specified using OWL (Web Ontology Language). Our approach, on the other hand, is more lightweight and allows arbitrary datasets to be processed, even if they are not described by an ontology. Our approach also does not require additional efforts from users and workflow task developers to learn OWL and to define missing ontologies.

Another Workflow Management System worth mentioning is Kepler cite:Ludaescher2006[]. This system is mature and has been used for various use cases for many years. Although there is an initiative to harness the possibilities of distributed computing in the _Distributed Execution Interest Group_, Kepler currently only works on a local computer and has not been transferred yet to the Cloud. Nevertheless, similar to Taverna, Kepler allows remote web services to be queried which enables distributed computing to a certain degree. For example, citet:Jaeger2005[] present an approach to use Kepler for the composition of web services to perform geospatial analysis and environmental modelling. They conclude that Kepler is a convenient system for discovering and composing web services. Our JobManager, on the other hand, is more flexible than Kepler and is specifically designed to run in a distributed environment.

A novel approach to distributed workflow execution is presented by citet:Balis2014[]. He introduces the HyperFlow workflow engine, a lightweight application written in JavaScript/Node.js. HyperFlow has a workflow model consisting of _functions_ and _signals_. Functions are written in JavaScript and have no dependencies other than the Node.js environment. In contrast to other Workflow Management Systems, HyperFlow functions do not have input and output ports. Instead, they exchange data through signals which are asynchronous events. HyperFlow supports for-each loops (_WCP-21_), choices (_WCP-4_), splits (_WCP-2_) and joins (_WCP-3_).

The fact that HyperFlow uses lightweight JavaScript functions makes it suitable for running in a Cloud environment and helps leverage the novel _serverless_ paradigm. _Serverless computing_ (also known as _Function as a Service_ or _FaaS_) is a way to execute code in the Cloud without requiring the user or software developer to maintain a virtual server. Serverless computing even works without containers as the whole life-cycle of the executed function is managed by the Cloud provider.

citet:Malawski2016[] has used HyperFlow to run the Montage workflow cite:Jacob2009[] on the Google Cloud Functions platform. His experiments confirm that serverless infrastructures can be used to run scientific workflows. However, he concludes that there are some limitations that need to be considered. Cloud providers typically limit the runtime of a serverless function (to 300 seconds in the case of AWS Lambda, for example, and to 60 seconds for Google Cloud Functions). Task granularity plays an important role. In our case, serverless functions are not applicable, because many of the geospatial processing services we execute can take longer than the limits set by the Cloud providers. In addition, the number of programming languages supported by serverless computing platforms is limited. They also require the functions to implement an interface which is typically vendor-specific. One of the major goals of our work, however, is to support arbitrary services and to avoid specialised interfaces.

In addition to the related work presented here, there are many other Workflow Management Systems, each of them having a different set of features and targeting different domains or use cases cite:Sheth1999[]. citet:Manolescu2000[] assumes there are so many systems because they often do not match the requirements of developers who want to leverage workflows in their software, or because they make assumptions that do not hold later. This is confirmed by citet:Ludaescher2009[] who state: "`Given the vast range of scientific workflow types [&hellip;] there is no single best or universal model of computation that fits all needs equally.`" In this section we have presented a selection of the most popular approaches to distributed management of scientific workflows. For an overview of the differences between further systems we refer to citet:Yu2005[] and citet:Deelman2009[].

[[sec:processing-service-orchestration]]
=== Service and component orchestration

In order to connect geospatial processing services, we define a lightweight service metadata model (see Section <<sec:processing-service-metadata>>) which can be used to specify inputs and outputs as well as other information about a service. The JobManager's Rule System uses this metadata to decide if two services are compatible to each other and if a valid process chain can be created for a given workflow (see Section <<sec:processing-rule-system>>).

Similar work has been done in the area of component orchestration. The Common Component Architecture (CCA), for example, defines a common interface description language for components used in scientific computing cite:Armstrong2006[] named _Scientific Interface Definition Language (SIDL)_ cite:Cleary1998[]. The Object Management Group has standardised the _CORBA Component Model (CCM)_ cite:ccm2006[]. In addition, there is the _Grid Component Model (GCM)_ which specifically targets applications running on large-scale heterogeneous Grid infrastructures cite:Baude2009[]. These models have been evaluated and used for Cloud computing applications by citet:Malawski2011[]. They describe how components of a distributed application can be packaged into platform-independent virtual appliances. citea:Malawski2011[] propose an API based on the general-purpose programming language Ruby with which components can be orchestrated to a scientific workflow.

There are other interface description languages from the area of Service-Oriented Architectures. The _Web Service Definition Language (WSDL)_, for example, describes how web services can exchange messages based on XML cite:wsdl2001[]. The Workflow Management Systems Taverna and Kepler support WSDL services (see Section <<sec:processing-workflow-management-systems>>). The _Web Services Business Process Execution Language (WS-BPEL)_ leverages WSDL and provides an XML-based language for the modelling of business processes cite:wsbpel2007[]. WS-BPEL can be used for web service orchestration and choreography--i.e. to model executable processes and to track message sequences between parties and sources cite:Peltz2003,Barros2006[].

In the geospatial community there are efforts to standardise the way web services can be orchestrated to implement distributed geospatial processing. The _OGC Web Processing Service (WPS) Interface Standard_ defines rules for the description of inputs and outputs of geospatial processing services cite:wps2015[]. This standard has been used to facilitate distributed applications running in the Web or on a Grid infrastructure cite:Lanig2008,Stollberg2007,Rautenbach2013,FriisChristensen2009[]. Another application is presented by citet:deJesus2012[] who have used the Taverna Workflow Management System to orchestrate WPS services and to analyse digital elevation models in a distributed environment. Compared to WPS, our approach is more light-weight and flexible. It allows for executing arbitrary processing services and not only web services.

citet:Patil2004[] have noted that in order to automatically discover web services that meet the requirements of a certain use case or process, mere interface descriptions are often not sufficient. Instead, they propose to add semantics as they are offered by ontologies. They argue that semantics helps them categorise services into application domains in order to improve the service discovery process, especially if users have to deal with thousands of services. However, they also note that the process highly depends on the quality of the selected ontologies. The approach for service selection we present in this chapter does not use ontologies. Instead, it uses a lightweight mechanism based on metadata and configurable rules.

In our approach, we use a rule-based system to generate executable process chains from workflow definitions. In the area of web service orchestration, rule-based systems have been used for business workflows, mostly to implement business rules cite:Weigand2008,Charfi2004[]. They have also been used to discover services and resources cite:Lutz2007[]. Compared to previous work, the rule-based system in our JobManager is used to a higher degree for multiple purposes. It selects services and data, and also generates process chains. If there are multiple ways to connect services to a suitable process chain, the JobManager decides which way to take. It also tries to generate chains that leverage data locality. This means it provides hints to the internal task scheduler, which in turn executes processing services on those compute nodes that contain the input data. This avoids time-consuming data transfers and reduces required bandwidth. The rule system also puts services accessing the same data into the same process chain, which is then executed on a single compute node. The JobManager's Rule System can therefore be compared to a query optimiser in a relational database cite:Chaudhuri1998[], or a multi-query optimiser trying to identify commonalities between multiple queries and to reuse resources cite:Roy2009[].

Rule-based systems have been used successfully for database query optimisation cite:Pirahesh1992[]. citet:Hong2009[] have applied a rule-based approach to multi-query optimisation and achieved good results although they propose to combine it with a cost-based approach. This has been tried for single queries by citet:Warshaw1999[] who claim to have achieved much better results than earlier work. Some database management systems such as Oracle have deprecated their rule-based optimiser in favour of a more comprehensive cost model cite:Ahmed2006[]. Query optimisation based on costs often leads to faster queries and is more generic than the rule-based approach, which can only cover a finite number of cases. The aim of rule-based approaches, on the other hand, is typically to create an extensible system. Rules are also easier to implement and maintain than a complex cost model.

Our JobManager is not a database management system so the requirements are different. The way services are orchestrated in our work depends on execution costs only to a certain degree. The main goal is to convert a high-level workflow to executable process chains. According to the requirements defined in Chapter <<chap:architecture>>, this should be done in an extensible way. The Rule System in the JobManager is configurable, which allows it to be adapted to different application domains as well as to various executing infrastructures. Since execution times of processing services vary to a large degree depending on the input data and are typically unknown in advance, we do not employ a cost model.

[[sec:processing-overview]]
== JobManager architecture overview

The main purpose of the JobManager is to control the processing of geospatial data by executing processing services (see Section <<sec:architecture-processing-services>>) on virtual machines in the Cloud. Figure <<img-jobmanager-architecture-overview>> gives an overview of the JobManager's software architecture.

[#img-jobmanager-architecture-overview]
.Software architecture of the JobManager
image::images/04_processing/jobmanager_architecture_2.pdf[scaledwidth="100%",align="center"]

The architecture consists of the following components:

* The _HTTP Server_ is the main entry point to the JobManager (see Section <<sec:processing-http-server>>).
* The _Controller_ processes workflows and oversees their execution. It loads metadata about processing services as well as the data to be processed, and calls the _Rule System_ to generate executable process chains (see Section <<sec:processing-controller>>).
* The _Rule System_ is responsible for generating process chains from workflows, service metadata and data metadata. These process chains are actual instructions telling the _Process Chain Manager_ how to execute processing services in the Cloud (see Section <<sec:processing-rule-system>>).
* The _Process Chain Manager_ executes process chains in the Cloud and monitors their execution (see Section <<sec:processing-process-chain-manager>>).

In addition, there is another component that does not directly belong to the JobManager. The _Processing Connector_ is a microservice running on the individual compute nodes in the Cloud. It receives requests from the _Process Chain Manager_ and executes the processing services locally on its respective compute node (see Section <<sec:processing-processing-connector>>).

In order to generate the process chains, the _Rule System_ makes use of metadata about services and the data to be processed. The _service metadata_ contains information about how to execute processing services. This includes a description of their parameters, cardinalities, supported input and output types, etc. (see Section <<sec:processing-service-metadata>>). The _data metadata_ describes the datasets stored in the Cloud, in particular properties such as accuracy, acquisition date and owner (see Section <<sec:processing-data-metadata>>).

The JobManager keeps workflows and process chains currently being executed in a database. This is necessary in order to _a)_ store results of workflows which can later be queried through the _HTTP Server_ and _b)_ keep track of running workflows so they can be resumed or restarted in case of a failure (see Section <<sec:processing-fault-tolerance>>). This database is also the main communication channel between the _Controller_ and the _Process Chain Manager_ (see Section <<sec:processing-controller>>).

We implemented the JobManager in Java using the Vert.x tool-kit cite:vertx2017[] which allows for creating reactive applications. According to the Reactive Manifesto such an application is responsive, resilient, elastic, and message-driven cite:reactivemanifesto2014[].

* **Responsive.** All operations in the JobManager happen asynchronously and non-blocking. The software is therefore always able to respond to user requests quickly.
* **Resilient.** The JobManager is resilient to failures and continues to operate in most cases--e.g. if a workflow execution has crashed or if a compute node was unavailable (see Section <<sec:processing-fault-tolerance>>).
* **Elastic.** Since the JobManager runs in the Cloud it can react to varying workload. The software itself can be deployed redundantly and scaled up easily due to the clustering features of Vert.x. In addition, the number of compute nodes the JobManager distributes workflow tasks to can be increased dynamically (see Section <<sec:processing-elasticity>>)
* **Message-driven.** Each JobManager component is implemented as a Vert.x verticle. Verticles are isolated from each other and operate independently. They communicate through messages that they send asynchronously over the Vert.x event-bus.

== Overview of workflow execution

Figure <<img-workflow-execution-2>> depicts how a workflow is processed by the system--from its definition in the workflow editor to the actual execution of processing services. Note that the figure does not show the architecture of the JobManager but the conceptual flow of a workflow through the system. It follows up on the overview of workflow execution in Section <<sec:architecture-jobmanager>> and shows which roles the individual components and data models play in the workflow execution.

The overall workflow execution is divided into two steps. In step a) the human-readable workflow definition is translated to a machine-readable representation. This process is described in detail in Chapter <<chap:workflow-modelling>>. Step b) is further divided into two sub-steps. First, the workflow is transformed to one or more executable process chains in step b.1). After this, in step b.2), each process chain is allocated to a compute node in the Cloud and executed.

[role="mt-1"]
**Step b.1).** The _HTTP Server_ receives the machine-readable workflow (see Section <<sec:processing-workflow>>). It validates the workflow and registers it in a database (see Section <<sec:processing-http-server>>). After this, it sends the workflow to the _Controller_ which is the main component responsible for the workflow execution (see Section <<sec:processing-controller>>). The _Controller_ calls the _Rule System_ and forwards the workflow as well as information about the processing services (_service metadata_, Section <<sec:processing-service-metadata>>) and data sets (_data metadata_, Section <<sec:processing-data-metadata>>). The _Rule System_ transforms the workflow to one or more _process chains_ which are executable descriptions of calls to processing services (see Section <<sec:processing-process-chain-model>>). It uses the _service metadata_ to decide which processing services need to be called and what parameters need to be provided to them. The _data metadata_ is used to decide which datasets should be processed. The resulting process chains are stored in a database.

[role="mt-1"]
**Step b.2).** The _Process Chain Manager_ regularly polls this database and looks for _process chains_ that have not been executed yet. The _Process Chain Manager_ is responsible for scheduling their execution (see Section <<sec:processing-process-chain-manager>>). This means it allocates each _process chain_ to an available compute node and sends it to an instance of the _Processing Connector_ running on this node. The _Processing Connector_ finally calls the processing services and collects their output (see Section <<sec:processing-processing-connector>>).

[role="mt-1"]
In the following sections each data model and component contributing to step b) is described in detail.

[#img-workflow-execution-2.top]
.Flow of a workflow through the system from its definition to the actual execution
image::images/04_processing/workflow-execution-2.pdf[scaledwidth="100%",align="center"]

[[sec:processing-data-models]]
== Data models

In this section we specify the data models of our JobManager. We first introduce the model for workflows. Then we specify which information must be provided about processing services so they can be executed by the JobManager (service metadata). We also describe the metadata that helps our system select the data to be processed (data metadata). Finally, we specify the data model for executable process chains which are generated by the Rule System based on the workflow model, the service metadata and the data metadata.

[[sec:processing-workflow]]
=== Workflow model

Figure <<img-processing-workflow-model>> depicts the data model for workflows executable by the JobManager. On submission, each workflow has a unique identifier, a name, a list of variables, and a list of actions. When the workflow is executed, the JobManager sets additional attributes denoting the time the execution has started, the current processing status, and finally the time the execution has finished.

[#img-processing-workflow-model]
.Class diagram of the workflow model
image::images/04_processing/abstract-workflow-model.pdf[scaledwidth="92%",align="center"]

The list of variables contains the workflow input parameters and declarations for variables used within the workflow. Each variable is a key-value pair, whereas the key is an identifier and the value is either a primitive boolean, number or string, or a list of primitive values. For pure variable declarations, the value can be undefined. Variable declarations are typically used to create links between the outputs and inputs of actions. Table <<tab:processing-workflow-model-variables>> lists examples for variables and their meaning.

[[tab:processing-workflow-model-variables]]
.Examples for workflow variables
[cols="17,41,45",frame=none,grid=rows,options="header"]
|===
| Example ID
| Example value
| Description

| input0
| /input-data/point-cloud.las
| A path to an input file

| output0
| /home/user/workflow134/terrain.tif
| A path to an output file

| resolution
| 50
| An input argument

| input1
| [ /input-data/point-cloud-01.las, &nbsp; &nbsp; &nbsp; /input-data/point-cloud-02.las ]
| A list of input files

| enum0
|
| A declaration of a variable that can be used as an enumerator in a for loop

| var0
|
| A declaration of a variable that can be used as an output parameter of a service and an input parameter of another one
|===

The workflow also contains one or more actions to execute. There are two types of actions: executable actions and for-each actions. Each action has input and output parameters. Executable actions refer to a processing service by its name and have additional parameters that should be passed by value to the service during execution. Parameter identifiers match the ones specified in the service metadata (see Section <<sec:processing-service-metadata>>).

For-each actions have a list of sub-actions that should be applied to a list of input data. Each for-each action also has an enumerator which is a variable the sub-actions can use to refer to an item in the input list. A for-action also makes use of another variable declaration which can be used to collect (or yield) output from sub-actions to an output list.

The workflow status is a string that is set by the JobManager during execution. Table <<tab:processing-workflow-statuses>> shows all possible values.

[[tab:processing-workflow-statuses]]
.Possible workflow statuses
[cols="25,75",frame=none,grid=rows,options="header"]
|===
| Status
| Description

| `ACCEPTED`
| The workflow was accepted by the JobManager's HTTP interface and scheduled for execution

| `RUNNING`
| The workflow is currently being executed

| `SUCCESS`
| The workflow execution finished successfully

| `ERROR`
| The workflow could not be executed

| `PARTIAL_SUCCESS`
| The workflow was executed, but some input datasets could not be processed successfully
|===

[[sec:processing-service-metadata]]
=== Service metadata

One of the main benefits of our approach is the ability to orchestrate existing processing services without requiring their developers to implement a special interface. For this purpose, our system relies on lightweight service descriptions stored in JSON files. We call these files _service metadata_. They contain information about the services (such as IDs, names, or descriptions) and describe input and output parameters.

Note that we define the service metadata format here and not a specific interface for the processing services. The service metadata format actually is a generic way to describe a service interface. It is designed to not impose any additional requirements on the services other than the ones described in Section <<sec:architecture-processing-services>>.

Table <<tab:processing-service-metadata>> lists all service metadata attributes for the description of a single processing service. Except for __runtime_args__, all attributes are mandatory.

[[tab:processing-service-metadata]]
.Service metadata: description of attributes
[cols="15,8,40,27",frame=none,grid=rows,options="header"]
|===
| Key
| Type
| Description
| Example

| id
| string
| Unique service identifier
| 35

| name
| string
| Human-readable name
| ResamplingOfPointCloud

| description
| string
| Human-readable description
| Resamples a point cloud

| type
| string
| Service type
| Resampling

| path
| string
| Relative path to the service executable in the service artefact
| bin/resample.sh

| os
| string
| Operating system
| linux

| runtime
| string
| Runtime environment (see Table&nbsp;<<tab:processing-service-metadata-runtimes>>)
| other

| runtime_args _(optional)_
| string
| Additional arguments to pass to the service runtime
|

| parameters
| array
| Array of parameters (see Table <<tab:processing-service-metadata-parameters>>)
| [{ ... }, { ... }, ...]

|===

The attributes _name_ and _description_ should contain human-readable strings. They are used in our system's main user interface and in the Workflow Editor described in Chapter <<chap:workflow-modelling>>. The editor can be used by domain experts to define their own workflows in a Domain-Specific Language (DSL). The editor's window contains a cue card with information about the language keywords, as well as the names and descriptions of processing services the domain experts can use in their workflows. The DSL has a generic _apply_ keyword allowing domain experts to directly call a processing service by its name (see Section <<sec:use-case-b-dsl-grammar>>). Since service names are represented by identifiers in the Domain-Specific Language they must not contain whitespaces (see Appendix <<app:combined-dsl-grammar>>). For the sake of consistency, all service names should be in camel case and begin with a capital letter. Valid examples are _ResamplingOfPointCloud_ or _SplineInterpolation_. The identifier _My cool new service_ is invalid.

The attribute '`type`' is a string defining a specific type of processing service. This attribute can be used by the Rule System to identify services that perform the same type of operation. The interpretation of this parameter depends on the environment the system is used in and on the registered processing services. Since there are so many different types we do not specify a certain list here. Example values are, however, '`Interpolation`' or '`Co-registration`'.

The metadata attribute '`path`' specifies the relative path to the service executable in the artefact or archive (e.g. ZIP file) containing the processing service.

The attribute '`os`' specifies the operating system the processing service requires. This information is used by the Rule System and the Process Chain Manager to distribute services to compatible nodes in the Cloud. Our implementation currently only supports a value of '`linux`', but other possible values are '`windows`' or '`macos`'.

The service metadata attribute '`runtime`' is used by the JobManager to decide which environment the processing service must run in. Table <<tab:processing-service-metadata-runtimes>> contains all possible values. If the attribute equals '`spark`', for example, the JobManager will treat the processing service as a Spark application and submit it to a compute node running a Spark cluster manager. The most generic value is '`other`' which means the service is an arbitrary executable program. In combination with the ability to run services inside Docker containers, our system in fact supports arbitrary programs.

[[tab:processing-service-metadata-runtimes]]
.Service metadata: runtime environments (possible values for the '`runtime`' attribute)
[cols="15,85",frame=none,grid=rows,options="header"]
|===
| Value
| Description

| shell
| Service is a bash script (Bourne-Again SHell)

| java
| Service will be executed in a Java Virtual Machine (JVM)

| python
| Service is a python program

| mono
| Service will be executed in the Mono runtime

| hadoop
| Service is an Apache Hadoop MapReduce job in a jar file

| spark
| Service is an Apache Spark application in a jar file

| other
| Service is an arbitrary executable program
|===

In addition, the optional attribute '`runtime_args`' can be used to pass arguments to the service runtime. For example, if the service is a Java program, '`runtime_args`' may be `-Xmx512M` specifying its maximum heap size.

The service metadata also contains a description of all processing service parameters. The attribute '`parameters`' is an array of JSON objects. Table <<tab:processing-service-metadata-parameters>> describes their structure.

[[tab:processing-service-metadata-parameters]]
.Service metadata: description of parameters
[cols="15,8,40,27",frame=none,grid=rows,options="header"]
|===
| Key
| Type
| Description
| Example

| id
| string
| Unique parameter identifier
| output_file_name

| name
| string
| Human-readable name
| outputFileName

| description
| string
| Human-readable description
| Output file

| type
| string
| Parameter type (either '`input`', '`output`', or '`argument`')
| output

| cardinality
| string
| Parameter cardinality ('`min..max`')
| 1..1

| default &nbsp; &nbsp; &nbsp; _(optional)_
| any
| Default value for this parameter
|

| data_type
| string
| Parameter type (see Table <<tab:processing-service-metadata-parameter-types>>)
| Point Cloud

| file_suffix
| string
| Output file extension or suffix
| .las

| label &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; _(optional)_
| string
| Parameter name on the command line
| `--output`

| dependencies _(optional)_
| array
| Parameters this parameter depends on
|

| conflicts &nbsp; &nbsp; _(optional)_
| array
| Parameters this parameter conflicts with
|

|===

The attribute '`id`' must be a string that identifies the parameter uniquely within the service metadata. A parameter description also contains a human-readable '`name`' and '`description`'. Just like the service name and description, these attributes are displayed in the Workflow Editor. The parameter name can become part of the Domain-Specific Language and must therefore not contain whitespace characters. It should be in camel case and start with a lower-case letter, so it can be differentiated from the service name.

The attribute '`cardinality`' defines the minimum and maximum number of occurrences of a parameter in a command line. If the minimum is `0` the parameter is optional. If it is at least `1` it is mandatory. The maximum must never be lower than the minimum. The character `n` means an indefinite number. Valid values for this parameter are, for example, `1..1` (the parameter must be provided exactly once), `0..1` (the parameter is optional but can be provided once), `1..4` (the parameter is mandatory and may be provided up to four times), `0..n` (the parameter is optional and may be provided an indefinite number of times).

Note that the optional attribute '`default`' can be used to specify a default value for mandatory parameters. This is useful if a processing service requires a specific parameter but it should be hidden from the user in the workflow description. Mandatory parameters with a default value become optional in the Domain-Specific Language.

The parameter description also contains an attribute named '`data_type`' that is used by the Rule System to determine if the output parameters of a service are compatible to the input parameters of a subsequent one. The attribute specifies the parameter type in terms of what kind of data it accepts. The value can either be one of the primitive types defined in Table <<tab:processing-service-metadata-parameter-types>> or an arbitrary string. In the latter case, the parameter refers to either an input or output file and denotes the type of the dataset in this file. Valid strings relevant to this thesis are, for example, `Point Cloud` or `Triangulation`.

[[tab:processing-service-metadata-parameter-types]]
.Service metadata: parameter types (possible values for the '`data_type`' attribute)
[cols="14,86",frame=none,grid=rows,options="header"]
|===
| Value
| Description

| integer
| The parameter is an integer value.

| float
| The parameter is a floating point number.

| string
| The parameter is a string.

| boolean
| The parameter is a boolean value. Valid values are `true`, `1`, `yes` and `false`, `0`, `no`. 

| directory
| The parameter is a string specifying a directory in the distributed file system containing input files.

| <other>
| An arbitrary string denoting the type of the dataset in an input or output file
|===

The attribute '`file_suffix`' is only valid if the parameter '`type`' is `output`. In this case it specifies a string that the Rule System will append to all generated output file names. This attribute is typically used to specify a file extension such as `.tif` or `.las`.

Parameters on the command line are often differentiated from each other by strings starting with a slash, a dash or a double-dash. The attribute '`label`' can be used to specify such a string. Valid values are, for example, `--input`, `--output`, `-i`, `-o`, or `/tolerance`.

Many programs accept parameters without labels. Instead, they rely on the order in which the parameters are given on the command line. As mentioned above, we do not require the processing services to implement a specific interface. In our parameter description the attribute '`label`' is therefore optional. The JobManager produces service calls with parameters that are in the same order as the descriptions in the service metadata attribute '`parameters`'.

The attributes '`dependencies`' and '`conflicts`' are optional arrays of parameter identifiers. They can be used to specify dependencies between parameters--e.g. if a certain parameter requires another one to be given as well--or conflicts--e.g. if two or more parameters are mutually exclusive.

[[sec:processing-data-metadata]]
=== Data metadata

In order to be able to automatically select datasets to be processed from the distributed file system, the JobManager makes use of _data metadata_. This metadata contains information about the datasets such as their extent or spatial resolution.

citet:ISO19115[] specifies a complex schema with a large number of attributes describing geographic information. This standard is well known in the geospatial community and widely adopted amongst data providers and users. The JobManager is able to process citea:ISO19115[] metadata and to use it in the Rule System to decide which datasets to process. The following is an excerpt of citea:ISO19115[] attributes giving examples how they can be utilised.

[cols="17,83",frame=none,grid=none]
|===
| *Attribute:*
| `MD_DataIdentification.extent`

| *Description:*
| The spatial extent of a dataset

| *Example:*
| Find datasets within a certain area.
|===

[cols="17,83",frame=none,grid=none]
|===
| *Attribute:*
| `MD_DataIdentification.spatialRepresentationType`

| *Description:*
| The type of information stored in the dataset

| *Example:*
| Select datasets containing grids, vector data, etc.
|===

[cols="17,83",frame=none,grid=none]
|===
| *Attribute:*
| `MD_Metadata.dateStamp`

| *Description:*
| The date and time the dataset was created

| *Example:*
| Compare two datasets and select the one that is newer.
|===

[cols="17,83",frame=none,grid=none]
|===
| *Attribute:*
| `MD_DataIdentification.spatialResolution`

| *Description:*
| The density of a dataset

| *Example:*
| Compare the spatial resolution of two datasets and find a trade-off between required quality and processing time. The dataset with the higher resolution might have a better quality, but the one with the lower resolution might be faster to process.
|===

[cols="17,83",frame=none,grid=none]
|===
| *Attribute:*
| `MD_DataIdentification.pointOfContact`

| *Description:*
| The party responsible for the dataset

| *Example:*
| A dataset that is provided or maintained by a certain party may be more reliable because the party has a higher credibility.
|===

[[sec:processing-process-chain-model]]
=== Process chain model

The process chain model describes a set of actions that are executed on the compute nodes in the Cloud as well as any dependencies between them. Process chains are created by the Rule System. The Process Chain Manager oversees the execution of process chains, and the Processing Connector uses them to create command lines for the processing services.

Figure <<img-processing-process-chain-model>> shows the class diagram of the process chain model. A process chain contains a set of executables that represent calls to processing services. An executable has a path pointing to the actual processing service executable (see the service metadata attribute '`path`' in Section <<sec:processing-service-metadata>>) as well as arguments that should be passed to the service. The arguments have labels, types and data types that correspond to the attributes from the service metadata. In addition, an argument refers to a variable containing the argument's value.

Since processing services are typically run in parallel, the set of executables in a process chain is not necessarily an ordered sequential list. Instead, an executable can have one or more predecessors specifying other executables in the same process chain that must be executed before this one.

[#img-processing-process-chain-model.top]
.Class diagram of the process chain model
image::images/04_processing/process-chain-model.pdf[scaledwidth="95%",align="center"]

Some attributes of the process chain model are needed by the Rule System and some are necessary for the Process Chain Manager and the Processing Connector. For example, process chains may have predecessors just like the executables. The Rule System uses this information to build a directed graph of process chains from a workflow. It keeps this information internal and only returns process chains to the Controller that do not have predecessors or those whose predecessors have already been executed successfully.

The same applies to containers. A container represents a runtime environment such as Docker or the Java Virtual Machine (see service metadata attribute '`runtime`' Section <<sec:processing-service-metadata>>). They wrap around executables and specify that a certain container application should be executed instead of the processing service itself. This information is needed by the Rule System to correctly generate calls to processing services.

In addition, the Rule System specifies couplings between executables that should be run within the same process chain and on the same compute node. This information is only necessary during the creation of process chains and will be ignored later on.

Arguments can be hidden, which means the Processing Connector will ignore them when it creates the command lines for the processing services. Instead, such arguments may be used by the Rule System internally to link executables together.

Finally, the working directory of an executable depends on the compute node where the process chain will be run. It will be set by the Processing Connector and ignored by the Rule System.

Note that multiple process chains may be created for a single workflow, depending on how much information is available at the time of creation and how the services should be distributed to the compute nodes. For more information, see Section <<sec:processing-rule-system>>.

[[sec:processing-components]]
== Components

In this section we describe the active components that participate in the processing of geospatial data in the Cloud. We give details on the individual parts of the _JobManager_, as well as the _Processing Connector_ and the processing services.

[[sec:processing-http-server]]
=== HTTP Server

The _HTTP Server_ is the main entry point to the JobManager. It receives incoming HTTP requests from clients such as our system's main user interface. Figure <<img-jobmanager-architecture-dynamic-structure-http>> depicts the control flow when a client sends a workflow to the JobManager.

[#img-jobmanager-architecture-dynamic-structure-http]
.Control flow in the JobManager when the HTTP Server receives an AWF from a client
image::images/04_processing/jobmanager_dynamic_structure_http.pdf[scaledwidth="75%",align="center"]

The flow starts in the upper left corner. The _Client_ sends a workflow to the _HTTP Server_ and then waits for an answer. Depending on the client's implementation, this most likely happens asynchronously. The _HTTP Server_ validates the workflow in terms of syntax and semantics. It immediately sends an error back to the _Client_ if the workflow is invalid. If it is valid, the _HTTP Server_ asynchronously sends the workflow to the _Controller_ which generates a unique identifier for it and then registers the workflow in its database. Before the _Controller_ executes the workflow, it sends the unique identifier back to the _HTTP Server_ which in turn forwards it to the _Client_ with an HTTP status code 202 (Accepted). This specific code means that the workflow was accepted and that it is now scheduled for execution, but the actual execution will happen at a later point in time--unless something prevents the workflow from being executed cite:rfc7231[prefix="see status code description in",locator="p. 52"]. It is important that the _Controller_ saves the workflow to a persistent database before it sends its answer. This ensures the workflow can be executed and the JobManager's answer will be valid even if there is a system failure before the execution starts (see Section <<sec:processing-fault-tolerance>>).

When the _HTTP Server_ has sent the answer to the client the _Controller_ will finally launch the workflow. This process is described in Section&nbsp;<<sec:processing-controller>>. While the workflow is being processed, the client may regularly poll its status by sending a request to the JobManager using the unique identifier it received earlier. In such a case, the _HTTP Server_ queries the _Controller_ to lookup the workflow's status in its database.

The following is a list of endpoints and operations the _HTTP Server_ supports.

==== pass:[<passthrough xmlns:fo="http://www.w3.org/1999/XSL/Format"><fo:block text-align-last="justify">POST workflow<fo:leader leader-pattern="space" />Endpoint: /</fo:block></passthrough>]

This endpoint can be used to send a workflow to the JobManager. The _HTTP Server_ will schedule it for execution and return a unique identifier with which the workflow's status can be queried.

[cols="29,172",frame=none,grid=rows,options="header"]
|===
| Parameter
| Description

| body
| Workflow that should be processed.

|===

[cols="29,86,86",frame=none,grid=rows,options="header"]
|===
| Status code
| Description
| Response body

| 202
| The workflow was accepted and is now scheduled for execution.
| A string that uniquely identifies the accepted workflow.

| 400
| The provided workflow was invalid.
| None.

|===

==== pass:[<passthrough xmlns:fo="http://www.w3.org/1999/XSL/Format"><fo:block text-align-last="justify">GET list of workflows<fo:leader leader-pattern="space" />Endpoint: /workflows</fo:block></passthrough>]

With this endpoint, a client can get information about all workflows registered in the JobManager's database including their status.

[cols="29,172",frame=none,grid=rows,options="header"]
|===
| Parameter
| Description

| offset
| The index of the first workflow to return, starting with zero. _(optional, default: 0)_

| limit
| The maximum number of workflows to return. _(optional)_

| sort
| The name of a property from the workflow model (see Section <<sec:processing-workflow>>) used to sort the returned list. Valid values are "`id`", "`name`", "`startTime`", "`endTime`", and "`status`" _(optional, default: "`startTime`")_

| order
| A positive number if the returned list should be sorted ascending, a negative number if it should be sorted descending. _(optional, default: -1)_

|===

[cols="29,86,86",frame=none,grid=rows,options="header"]
|===
| Status code
| Description
| Response body

| 200
| The workflow list was generated successfully.
| A JSON array containing all workflows according to the model defined in Section <<sec:processing-workflow>>.

| 400
| One of the given parameters was invalid.
| None.

|===

==== pass:[<passthrough xmlns:fo="http://www.w3.org/1999/XSL/Format"><fo:block text-align-last="justify">GET workflow details<fo:leader leader-pattern="space" />Endpoint: /workflows/:id</fo:block></passthrough>]

This endpoint can be used to get information about a workflow registered in the JobManager's database including its status.

[cols="29,172",frame=none,grid=rows,options="header"]
|===
| Parameter
| Description

| id
| The unique identifier returned by the HTTP Server when the workflow was submitted.

|===

[cols="29,86,86",frame=none,grid=rows,options="header"]
|===
| Status code
| Description
| Response body

| 200
| The workflow was retrieved successfully from the database.
| A JSON object representing the workflow according to the model defined in Section <<sec:processing-workflow>>.

| 404
| The requested workflow was not found in the database.
| None.

|===

==== pass:[<passthrough xmlns:fo="http://www.w3.org/1999/XSL/Format"><fo:block text-align-last="justify">DELETE workflow<fo:leader leader-pattern="space" />Endpoint: /workflows/:id</fo:block></passthrough>]

With this endpoint, a workflow can be removed from the Controller's database and the execution can be cancelled. This operation also deletes all generated process chains belonging to the workflow.

[cols="29,172",frame=none,grid=rows,options="header"]
|===
| Parameter
| Description

| id
| The unique identifier returned by the HTTP Server when the workflow was submitted.

|===

[cols="29,86,86",frame=none,grid=rows,options="header"]
|===
| Status code
| Description
| Response body

| 204
| The workflow was deleted from the database or it did not exist in the first place (the operation is idempotent).
| None.

|===

[[sec:processing-controller]]
=== Controller

The _Controller_ is one of the main components of the JobManager. It receives workflows from the HTTP Server, calls the Rule System (see Section <<sec:processing-rule-system>>) to generate process chains for these workflows, and stores them in a database so they can be executed by the Process Chain Manager (see Section <<sec:processing-process-chain-manager>>). It also regularly looks up process chain results to update the status of workflows currently being executed.

The database maintained by the Controller contains received workflows and generated process chains. It serves three purposes:

* The stored workflows can be returned to the client on request (see Section <<sec:processing-http-server>>).
* Since the database is a persistent representation of the JobManager's state, it can be used to continue or restart a workflow execution in case of a system failure without losing information (see Section <<sec:processing-fault-tolerance>>).
* The database is used as the main communication channel between the Controller and the Process Chain Manager. Both components do not communicate with each other directly but alter the contents of the database and regularly look for updates.

Figure <<img-jobmanager-architecture-dynamic-structure-controller>> depicts the control flow in the JobManager when the Controller has received a workflow from the HTTP Server and monitors its execution. It extends Figure <<img-jobmanager-architecture-dynamic-structure-http>> in which it represents the grey transition box labelled "`execute workflow`".

[#img-jobmanager-architecture-dynamic-structure-controller.top]
.The control flow in the JobManager while the Controller executes a workflow
image::images/04_processing/jobmanager_dynamic_structure_controller.pdf[scaledwidth="90%",align="center"]

First, the Controller loads the service metadata and the data metadata. It then calls the Rule System and forwards metadata as well as the workflow. The Rule System puts this information in its working memory and fires all rules until it has either generated new process chains or until there are no further rules to be fired.

If the Rule System has created new process chains, the Controller stores them in its database. As we show in Section <<sec:processing-process-chain-manager>>, the Process Chain Manager picks up the process chains from the database and executes them in the Cloud. In the meantime, the Controller regularly polls the database and checks if there are new process chain results added by the Process Chain Manager. If the Controller finds a failed process chain in the database it will abort the execution of the whole workflow. In this case, it will register the results of successful process chains belonging to the same workflow in the database and set the workflow's status to `PARTIAL_SUCCESS`. If the workflow does not have any successful process chains, the Controller will set the status to `ERROR`.

If the Controller has polled the database and all process chains of the workflow have succeeded, the Controller calls the Rule System again to see if it generates any more process chains. This time the Controller also forwards the results from all previous process chains of the workflow currently being executed to the Rule System (in particular their statuses and the created output files) so it can reason about them as well.

The whole process continues until the Rule System finishes without generating more process chains. In this case the workflow is considered finished since there are no further process chains to be executed. The Controller registers the workflow results in the database, sets the workflow's status to `SUCCEEDED`, and stops the execution.

Note that since the Controller is implemented in an event-based, asynchronous way it can monitor the execution of multiple workflows at the same time.

[[sec:processing-rule-system]]
=== Rule System

The Rule System is responsible for creating executable process chains from workflows. It consists of two parts: a working memory and a set of production rules. The working memory contains the facts the rule system can reason about. In our case these are the data metadata, the service metadata and the workflow to execute. In addition, the Controller inserts artificial facts for successfully executed process chains. This is necessary so that the Rule System can generate and return more process chains (see the paragraph named "`Result`" below).

Production rules typically consist of a left-hand side and a right-hand side containing conditions and actions respectively. The Rule System evaluates the facts in the working memory against the conditions. If all conditions of a rule become true it will "`fire`", which means the actions will be executed. Rules that are firing may change the contents of the working memory. Other conditions may then become true and hence other rules will fire. This way, rules can be connected to a network performing complex operations. In our case we use production rules to quickly reason about data metadata, service metadata and workflow actions. Depending on this information we prepare optimized process chains that can be executed in a distributed way in the Cloud by the Process Chain Manager. Using a production rule system also allows us to keep this process configurable and adaptable to different use cases and scenarios.

The production rules are divided into three phases that are executed sequentially. First, the Rule System selects the datasets to process, then finds processing services, and finally generates the process chains.

==== Select datasets

In Chapter <<chap:workflow-modelling>> we present our Domain-Specific Language for workflow modelling. This language allows users to either specify a dataset to process directly by its filename on the distributed file system (using placeholders; see Section <<sec:use-case-b-dsl-grammar>>) or to just specify a data type such as '`PointCloud`'. In addition, the keyword '`recent`' allows users to select the most up-to-date dataset from a set of candidates.

These language features can be mapped to production rules. For example, the workflow expression '`latest PointCloud`' can be implemented by creating two rules: one that reasons about the data metadata and creates a set of datasets with the type '`PointCloud`', and another one that selects the most up-to-date dataset from this set.

Further rules can be implemented, for example, to select datasets by their spatial extent, by a specific owner, or based on the permissions a user has (see Section <<sec:processing-data-metadata>> for more examples). As mentioned above, the Rule System is a dynamic and configurable part of our system that allows us to adapt the behaviour to various requirements.

==== Select services

The Rule System also selects the processing services that are applied to the chosen datasets in a workflow. For this, it reasons about the service metadata and the individual actions in the workflow as follows:

. The first production rule creates a set of matching candidates for each workflow action based on the service name, the parameters, parameter types, cardinalities, etc.
. The Rule System also considers subsequent services and checks if their input and output parameters are compatible to each other in terms of data types. This further reduces the set of candidates.
. Another production rule selects the service with the highest semantic version from the remaining set of candidates.
. If the set is empty, the Rule System aborts the workflow execution, as the workflow is apparently invalid. Otherwise, a final rule converts the selected service candidate to an `Executable` instance from the process chain model (see Section <<sec:processing-process-chain-model>>).

Again, the Rule System allows us to keep our architecture configurable. For example, if for a certain use case, it is necessary to always select a service with a specific version number (e.g. because it is the most reliable one known to work well with the input datasets from this use case), or if a certain group of users has licenses for some processing services but not for others, this can be configured in the Rule System.

==== Generate process chains

The production rules selecting the processing services convert the service candidates to `Executable` instances from the process chain model (see Section <<sec:processing-process-chain-model>>). Next, these ``Executable``s need to be linked and put into process chains, which will be executed by the Process Chain Manager in the Cloud. All ``Executable``s in a process chain are executed on the same compute node, but multiple process chains can run in parallel in the Cloud. Process chains are created as follows:

. First, for-each actions are _unrolled_, which means they are replaced by copies of their sub-actions whereas the number of copies depends on the list of inputs the for-each action is applied to. For example, consider a for-each action F with the sub-actions A and B. If F should be applied to five inputs, A and B will be copied five times and F will be removed from the working memory. The inputs of A and B will be adapted accordingly.
. The parameters of workflow actions are converted to arguments for the respective ``Executable``s. This includes adding default values for optional parameters, appending file suffixes, etc.
. If required, the individual ``Executable``s are linked to further processing services that should be executed either before or after the one the ``Executable`` refers to. This includes adding services for data conversion, monitoring, or other purposes.
. ``Executable``s referring to processing services that require a special environment are wrapped into a `Container`. This allows the Rule System and the Processing Connector to generate correct command lines.
. ``Executable``s are finally connected to a directed graph by comparing the `Variable` instances of their input and output arguments. An ``Executable`` with an output argument that equals an input argument of another one becomes a predecessor of this ``Executable``.

The graph of executables is then converted to process chains according to the following constraints:

* Create a new process chain for every ``Executable`` that does not have a predecessor.
* Keep couples (i.e. processing services that need to be executed on the same compute node) together.
* Try to optimize the process chains and leverage data locality by putting ``Executable``s that refer to the same datasets in the same process chain.
* Try to leverage parallelisation as much as possible by splitting process chains at junction points and putting the individual paths in separate process chains. Keep the dependencies between the ``Executable``s by correctly setting process chain predecessors.

The last point is very important for our system as it allows us to create independent process chains that can be executed in parallel on multiple compute nodes. Figure <<img-process-chain-parallelisation>> illustrates an example of a process chain and how it is split into multiple ones. ``Executable`` 1 has three outputs that should be processed in parallel by ``Executable``s 2 to 7. ``Executable`` 8 merges the outputs together. The process chain can be split into five smaller ones. Process chains 2 to 4 each contain two ``Executable``s. They can be run in parallel in the Cloud because they do not have dependencies to each other. All ``Executable``s in a process chain are run on the same compute node to leverage data locality. The execution of process chain 5 can only commence once chains 2 to 4 are finished. This is ensured by the predecessor dependencies between the process chains.

[#img-process-chain-parallelisation]
.A process chain that is split into multiple ones to leverage parallelisation
image::images/04_processing/process-chain-parallelisation.pdf[scaledwidth="100%",align="center"]

==== Data locality optimisation

As described above, each process chain is executed on exactly one compute node. This keeps services that access the same data together. For example, a service that writes a certain file and a subsequent one reading this file are put into the same chain--as long as the constraints from the previous subsection are met. This avoids data unnecessarily being transferred from one compute node to another, which would increase network usage and possibly slow down workflow execution.

Another optimisation that the JobManager performs is based on the location of input files from the original data set the workflow is applied to. Before the workflow is executed, the JobManager creates an index of all files that will be processed and determines their location in the Cloud. It puts this information in the working memory of the Rule System. Based on this, the Rule System creates hints for the Process Chain Manager (see Section <<sec:processing-process-chain-manager>>) telling it on which node a generated process chain should be executed. Again, this reduces the need to transfer large amounts of data. Instead, the processing services are transferred to (or executed on) the compute nodes that contain the requested files. Data locality optimisation is one of the approaches that help the JobManager to make best use of available Cloud resources.

As described in Chapter <<chap:architecture>> we use a distributed file system for data storage. Since such a file system supports replication and several copies of an input file may be located on multiple compute nodes, the hints that the Rule System forwards to the Process Chain Manager may contain several locations. The Process Chain Manager is optimised for high throughput. Based on the hints it will select an available compute node to execute the process chain on. If none of the available nodes matches the locations in the hint, it will either delay the process chain and continue with others or execute it on any available node--whichever option is faster.

==== Result

At the end of the reasoning process the Rule System returns the process chains that are ready for execution--i.e. those without a predecessor or whose predecessors have already been executed successfully.

As mentioned above, whenever a process chain was executed successfully, the Controller adds an artificial fact into the Rule System's working memory including the process chain's status and its outputs--i.e. the files created by the processing services. This allows the Rule System to apply for-each actions to these outputs and to generate the correct number of process chains. The ability to produce process chains (or workflow branches) dynamically at runtime without a priori knowledge at design time corresponds to workflow control-flow pattern WCP-14 (see Section <<sec:processing-workflow-patterns>>). This differentiates our approach from many other workflow management systems for distributed computing.

[[sec:processing-process-chain-manager]]
=== Process Chain Manager

The Process Chain Manager distributes process chains to compute nodes in the Cloud. It oversees their execution and handles results and failures. Figure <<img-jobmanager-architecture-dynamic-structure-process-chain-manager>> illustrates the component's main loop. 

The Process Chain Manager periodically polls the JobManager's database for process chains. If there is a new chain that has just been generated by the Rule System and that is now ready for execution, the Process Chain Manager selects a compute node to execute it on (according to the algorithm described below). If there is a node available, the Process Chain Manager sends the chain to the Processing Connector running on this node and sets its status to `RUNNING` in the database. Otherwise, it returns to the start and retries the process in the next loop.

Process chains that are currently `RUNNING` are treated differently. The Process Chain Manager first requests the current status from the Processing Connector that runs the process chain. If it is still running, the Process Chain Manager just returns to the start and continues with periodic polling. Otherwise, if the process chain has finished in the meantime, the Process Chain Manager registers its results (i.e. the output files written) in the database and finally returns to the start.

[#img-jobmanager-architecture-dynamic-structure-process-chain-manager.top]
.The main control-flow in the Process Chain Manager
image::images/04_processing/jobmanager_dynamic_structure_process_chain_manager.pdf[scaledwidth="72%",align="center"]

==== Error handling

The Process Chain Manager handles failures in the following way:

* If the connection to a compute node failed or timed out, or if the Processing Connector returned HTTP status code 500, the Process Chain Manager selects another node and retries the operation after a short delay of up to five seconds.
* If a configurable number of other nodes also fail, the process chain's status is set to `ERROR`. It will not be retried.
* If the Processing Connector successfully returns the result of a process chain but the chain has failed (e.g. because one of the processing services failed with a non-zero exit code, see Section&nbsp;<<sec:architecture-processing-service-requirements>>), its status is set to `ERROR` and it is not retried.

==== Node selection

There are a number of algorithms that can be used to select a compute node on which a process chain should be executed. citet:Russell2004[] suggest _Random Allocation (workflow resource pattern R-RMA)_, _Round-Robin Allocation (R-RRA)_, or _Shortest Queue (R-SHQ)_. We also consider _First In &ndash; First Out (FIFO)_ which is a variation of _Shortest Queue_.

* **Random Allocation.** In this algorithm the workflow engine (in our case the Process Chain Manager) keeps a list of resources (i.e. compute nodes) from which it selects one at random.

* **Round-Robin Allocation.** This algorithm aims for an even utilisation of all resources. It selects compute nodes one after the other from the list. If the last node has been reached, the algorithm starts from the beginning.

* **Shortest Queue.** The Process Chain Manager keeps a list of all nodes and a queue of running tasks (in our case process chains) for each node. It selects the node with the shortest queue which is supposed to be the one with the most resources available.

* **First In &ndash; First Out (FIFO).** All available compute nodes are kept in a queue. The Process Chain Manager selects the first one and removes it from the queue. Nodes that have finished executing a process chain are put back at the end of the queue. If the queue is empty, the Process Chain Manager has to wait until a node becomes available again.

_Shortest Queue_ is optimised for maximum throughput. We use this algorithm because we want to make use of as much resources as available and to process workflows as fast as possible.

In Chapter <<chap:evaluation>> we will see that there are typically a lot more process chains ready to be executed than available compute nodes. In order to prevent the nodes from being overloaded, we limit the size of the queue of process chains per node. The limit can vary amongst the individual compute nodes. A value of 1 basically reduces the algorithm to _First In &ndash; First Out_. Since we often deal with processing services that only make use of one CPU core, but the compute nodes offer multiple cores, it is advisable to set the queue size for each node to the respective number of available CPU cores.

Note that the node selection process is not only based on available slots in the queue but also depends on the capabilities offered by a node. The Process Chain Manager analyses the process chains and the service metadata and collects a list of requirements the processing services have towards the environment they are executed in. For example, if the service metadata specifies that a certain service requires Apache Spark the Process Chain Manager will limit the list of compute nodes from which to select to those which have Apache Spark installed.

In addition, as described in Section <<sec:processing-rule-system>> the Rule System performs data locality optimisation to reduce the amount of data transferred over the network and to improve workflow execution performance. It generates hints for the Process Chain Manager to tell it on which nodes it should run generated process chains. The Process Chain tries to follow the hints and assign process chains to the given compute nodes as long as this does not prevent high throughput. If all of the given compute nodes are currently busy, the Process Chain Manager will either delay the execution of the process chain and continue with another one or execute it on any available node--depending on which option is faster. This means the hints generated by the Rule System are only a means to prioritise certain compute nodes over others, but not a guarantee that the process chain will actually be executed on these nodes.

Another way of optimising throughput is to use _Random Allocation_ or _Round-Robin Allocation_ and to keep a queue at the side of the compute node in the Processing Connector. This way the Processing Connector could monitor resource usage on the compute node and decide on its own when to execute the process chain. However, this could lead to free resources being unused on other compute nodes whose queue is already empty. This approach would therefore require a way for the Process Chain Manager to intervene and to deallocate a process chain (whose execution has not started yet) from a node and to reallocate it to another one.

In order to achieve best results, such an algorithm would also require some kind of knowledge about the processing services and their expected resource usage. Otherwise deciding when to start a process chain containing multiple service calls with different resource requirements would be mere guessing. _Shortest Queue_, on the other hand, is more predictive, simpler to implement, and less error-prone. As we will show in Chapter&nbsp;<<chap:evaluation>> it achieves a reasonable throughput.

Note that scheduling algorithms known from the domain of operating systems such as any pre-emptive algorithm or priority-based ones that consider the amount of time a task may take do not apply here. Our system does not support pausing and resuming of process chains, nor do we have any information about the expected runtime or resource usage of processing services and hence process chains.

We could assign priorities to process chains in order to be able to execute important workflows before other ones. Such a prioritisation could be done in the Rule System or configured by the user in our system's main user interface. Special care would have to be taken in this case to prevent starvation--i.e. process chains that are never allocated to any node because there always is another one with a higher priority. More complex and sophisticated scheduling algorithms are, however, not the focus of this work and therefore beyond its scope.

[[sec:processing-processing-connector]]
=== Processing Connector

On each compute node in the Cloud there is a Processing Connector instance which receives process chains from the Process Chain Manager through HTTP. It takes care of executing processing services according to the order determined by the predecessor dependencies in the received process chains. For each process chain, it also collects the service outputs and provides them through its HTTP interface to the Process Chain Manager. If one of the outputs is a directory the Processing Connector will recursively collect all files in this directory instead. This allows the Rule System later to reason about the files and to create the correct number of process chain branches for the sub-actions of for-each actions (see Section&nbsp;<<sec:processing-rule-system>>). It is also key to one of the benefits of our approach--namely that the JobManager does not require a priori design-time knowledge. The number of instances of a specific processing service can depend on the output of a previous one. Other workflow management systems require all variables to be available at design time (see Section <<sec:processing-workflow-patterns>>).

The following is a list of endpoints and operations the Processing Connector's HTTP interface supports.

==== pass:[<passthrough xmlns:fo="http://www.w3.org/1999/XSL/Format"><fo:block text-align-last="justify">POST process chain<fo:leader leader-pattern="space" />Endpoint: /processchains</fo:block></passthrough>]

This endpoint can be used to send a process chain to the Processing Connector. The chain will be validated and then scheduled for immediate execution. The HTTP interface will return a unique identifier with which the process chain's status and results can be queried.

[cols="29,172",frame=none,grid=rows,options="header"]
|===
| Parameter
| Description

| body
| The process chain that should be executed.

|===

[cols="29,86,86",frame=none,grid=rows,options="header"]
|===
| Status code
| Description
| Response body

| 202
| The process chain was accepted and is now scheduled for immediate execution.
| The process chain's ID.

| 400
| The provided process chain is invalid or incompatible to the compute node (e.g. because of missing requirements).
| None.

| 500
| Internal server error (e.g. if the process chain could not be scheduled or if another error has happened).
| None.

|===

==== pass:[<passthrough xmlns:fo="http://www.w3.org/1999/XSL/Format"><fo:block text-align-last="justify">GET process chain status and results<fo:leader leader-pattern="space" />Endpoint: /processchains/:id</fo:block></passthrough>]

With this endpoint, a client can get information about the status of a process chain. If the chain was executed successfully, the response will also include the results (i.e. the files written by the executed processing services). The status values that can possibly be returned are the same as the ones in the workflow model (see Section <<sec:processing-workflow>> and in particular Table <<tab:processing-workflow-statuses>>).

[cols="29,172",frame=none,grid=rows,options="header"]
|===
| Parameter
| Description

| id
| The process chain's ID.

|===

[cols="29,86,86",frame=none,grid=rows,options="header"]
|===
| Status code
| Description
| Response body

| 200
| The operation was successful.
| A JSON object (see details below).

| 404
| The requested process chain is unknown.
| None.

| 500
| The process chain's status and results could not be retrieved (e.g. because of an I/O error).
| None.

|===

The operation's response is a JSON object containing the process chain's status and--if it was executed successfully--its outputs. The outputs are represented by a JSON object whose keys are IDs of process chain arguments and values are arrays of names of written files. The following is an example response:

[source]
----
{
  "status": "SUCCESS",
  "output": [{
    "id": "argument1",
    "value": [ "/path/to/point_cloud.las" ]
  }, {
    "id": "argument2",
    "value": [
      "/tmp/output1.json",
      "/tmp/output2.json"
    ]
  }]
}
----

[[sec:processing-fault-tolerance]]
== Fault tolerance

Due to the characteristics of distributed systems, there are many sources for potential failures cite:deutsch1994[]. A good strategy to create a stable and resilient system is therefore not to try to avoid failures but to embrace them cite:robbins2012[]. This means the system should be designed to be able to cope with failures and to continue to operate and provide service (maybe only partly) until the failure has been resolved cite:Nygard2007[].

To summarise the component descriptions from the previous sections, we implemented measures to make the JobManager resilient and tolerant to the following common failures:

[role="mt-1"]
**Chain reactions and cascading failures.** A failure caused by one component can often cascade through other components in a distributed system and cause further failures. For example, if service A becomes unreachable, service B can become unavailable too because it just sent a request to A and is now waiting for an answer. This can lead to another service C becoming unresponsive because it needs to wait for B, etc.

Chain reactions and cascading failures are often caused by blocked threads and synchronous calls to remote resources. We avoid such situations, because the JobManager works _asynchronously_ and _event-based_. All components continue to operate and stay responsive even if a component they depend on becomes unavailable.

In addition, the microservice architectural style allows us to implement the _bulkhead pattern_ cite:Nygard2007[locator=96]. The individual components (i.e. microservices) have a high coherence and are loosely coupled. They run in separate processes and often on separate virtual machines. If one of the services crashes or if one virtual machine becomes unavailable, the rest of the system is not affected and can continue to operate.

[role="mt-1"]
**Slow responses.** Every request made in a distributed system consumes resources, even if it is asynchronous. A service that responds slowly can become a source of error, in particular if the response is actually a failure and the service that performed the request unnecessarily had to keep resources.

In the JobManager we use _timeouts_ to abort asynchronous operations. However, if possible we try to _fail fast_ which means we try to identify and propagate a failure as quickly as possible. If there is a problem in the Processing Connector or in the Process Chain Manager, the status of affected process chains will immediately be set to `ERROR`. The Rule System does not produce process chains for erroneous outputs and the Controller aborts the workflow execution if there are no more process chains to execute. This approach has two benefits: resources are not occupied longer than necessary, and the users are informed early about problems, so they do not have to wait for results of failed workflows.

[role="mt-1"]
**Unreachable services.** In a distributed environment a service may become unreachable for different reasons: network failures, crashed service, crashed virtual machine, etc. If the problem is only temporary the service will become available again after a short period. This also applies if the failure has been detected and the service or the virtual machine was restarted (or otherwise repaired). The usual strategy to detect if a service is working again is to retry a failed call several times after short delays. However, if a service is known to be currently unavailable further calls to it are useless and should be postponed until it can be reached again.

[#img-circuit-breaker.bottom]
.Petri net for the Circuit Breaker pattern
image::images/04_processing/circuit-breaker.pdf[scaledwidth="100%",align="center"]

A strategy that implements this is the _Circuit Breaker pattern_ cite:Nygard2007[locator=93]. A circuit breaker is a finite state machine that can have three states: closed, open and half open (see Figure&nbsp;<<img-circuit-breaker>>). The default state is closed which means service calls are allowed. As soon as the circuit breaker detects a configurable number of failures, it goes into the open state. In this state service calls are blocked (they fail fast) and do not occupy further resources (the service is known to be unavailable). The circuit breaker stays in this state for a configurable amount of time and then goes into the half-open state. If the first service call succeeds in this state, the circuit breaker will return to the closed state (the service is available again). Otherwise, it will go back to the open state and block calls.

We use the Circuit Breaker pattern in various places of our architecture. The most notable one is the Process Chain Manager where we detect unreachable compute nodes with it and avoid further calls to them. As we will see in Section <<sec:evaluation-availability>>, this helps us to recover from failures and to successfully execute a workflow even if some compute nodes are temporarily unavailable.

[role="mt-1"]
**Single Point of Failure.** The JobManager can become a Single Point of Failure (SPOF) in our system. This means that if the JobManager fails the whole system will not work as expected. In order to avoid that the JobManager becomes an SPOF, we have to deploy it redundantly. As described in Section <<sec:processing-overview>> we used Vert.x for our implementation. This tool-kit allows microservices to run in clustered high-availability mode. This means that the JobManager can be distributed to multiple processes on separate virtual machines. Vert.x takes care of connecting these processes to one virtual application.

Since we split up the JobManager into multiple independent verticles (HTTP Server, Controller, Rule System, and Process Chain Manager), we can deploy multiple instances of them to separate virtual machines. If one of the verticles fails, another instance will take over. If one of the virtual machines crashes, there will still be another one to handle incoming requests. In high-availability mode, Vert.x will take care of keeping the number of verticle instances the same all the time. If one of the verticles becomes unavailable, Vert.x will start a new instance on another virtual machine.

The JobManager's application state (workflows, process chains and their statuses) is completely stored in a database. We do not have to take special care to transfer work from a failed verticle to another one. The Controller and the Process Chain Manager regularly poll the database. If one of the verticles needs to take over from another one, it will read the state from the database automatically the next time it polls it.

[role="mt-1"]
**System crash.** The fact that we store the application state in a database also helps us to recover from system crashes. If the whole system fails--e.g. due to a power outage in the data centre--we can continue to execute workflows as soon as the system is up and running again. The Controller and Process Chain Manager regularly poll the database. After the JobManager has started, regular polling begins immediately. If the Process Chain Manager finds a process chain in the database that has not finished yet it will automatically execute it.

Work that has been done before--e.g. if half of the process chain was already executed--is not cached. The whole process chain will be executed again. However, since the processing services are idempotent (see Section <<sec:architecture-processing-services>>) the overall result of the workflow will still be correct.

In order to make sure that this mechanism actually works, the initial request from the client to create a new workflow is only answered with HTTP status code 202 (Accepted) if the workflow was successfully stored in the database (see HTTP POST operation in Section <<sec:processing-http-server>>).

[[sec:processing-scalability]]
== Scalability

The JobManager has to work reliably under a high workload and regardless of how much data should be processed. citet:Bondi2000[] lists a number of factors that can influence the behaviour of a system and thus affect its ability to scale. In our case, we have to consider the following factors:

[role="mt-1"]
**Number of users (Load Scalability).** Our system should be able to handle multiple users and work properly regardless of how many users access it at the same time. On the one hand, we achieve responsiveness through our approach to implement the JobManager in an event-based and asynchronous manner. On the other hand, our system is elastic and can handle a growing number of users (see Section <<sec:processing-elasticity>>).

[role="mt-1"]
**Data size (Space Scalability).** The JobManager does not process geospatial datasets itself but delegates work to processing services. It therefore does not depend directly on data volume. However, geospatial datasets are typically split into smaller files that are processed individually. Workflows can become very large, in particular if they contain many for-each actions iterating over a large number of files. To accommodate this, the Rule System splits workflows into smaller process chains. As described in Section <<sec:processing-controller>> the Controller calls the Rule System in a loop until it returns no more process chains. This way, the number of chains held in memory at the same time can be kept at a reasonable size.

[role="mt-1"]
**Number of processing services and compute nodes (Structural Scalability).** The JobManager should be able to handle many processing services in different versions. It should also be able to distribute work to many compute nodes in the Cloud. In fact, these two factors could become an issue in the JobManager since both the list of processing services and the list of compute nodes are kept in memory. However, the number of items in these lists is predictable and finite. They also do not occupy very much memory. We did not experience problems with this in practise.

[role="mt-1"]
**Data location (Speed/Distance Scalability).** A distributed system should be able to work properly, regardless of where data and computational resources are located and how long it takes to transfer information. We accommodate this with our event-based asynchronous approach. The JobManager does not block when performing asynchronous requests. It always stays responsive. Responses from asynchronous operations are handled as soon as they arrive.

[[sec:processing-elasticity]]
== Elasticity

The JobManager works in an environment that is highly dynamic. Compared to a Cluster or a Grid, resources in a Cloud can be automatically provisioned and de-provisioned depending on the current workload. This property is called _elasticity_ cite:Herbst2013[].

Elasticity can become important in the JobManager as soon as there are multiple users working with the system at the same time and/or if these users have time constraints--such as in the urban use case illustrated in Section <<sec:introduction-use-cases>>, or in an emergency case. The JobManager should be able to handle a growing number of users and concurrent workflow executions. It should also be able to meet time constraints by making use of additional Cloud resources if necessary.

[role="mt-1"]
**Growing number of users and concurrent workflows.** The JobManager is implemented in an event-based asynchronous way. It can handle a large number of requests and always stays responsive (see Section <<sec:processing-scalability>>).

As described in Sections <<sec:processing-controller>> and <<sec:processing-process-chain-manager>> the Controller as well as the Process Chain Manager do not keep transient state but regularly poll a database for running workflows and process chains. This allows them to handle multiple workflow executions concurrently.

As described in Section <<sec:processing-overview>>, the JobManager is implemented in Vert.x. This framework enables us to distribute multiple instances of the JobManager's components to several virtual machines in the Cloud. If the workload becomes too high, we can add more virtual machines and more instances dynamically during runtime. Since the JobManager does not keep transient state, we can even do this during the execution of workflows.

[role="mt-1"]
**Time constraints.** If there are constraints that require the JobManager to finish certain workflows in a given amount of time, regardless of how many other workflows are currently running, we can increase the number of compute nodes dynamically. The JobManager uses the Vert.x Config module with which an application's configuration can be changed during runtime. This allows us to add and remove compute nodes, even during the execution of workflows.

Initially, we planned to scale out automatically and to let the JobManager request more Cloud resources if necessary based on configurable rules. However, the rules would have to be implemented very carefully. Otherwise, this approach could have led to excessive use of resources and to high costs. We therefore propose to handle this issue on the level of the Cloud infrastructure. Most Cloud administration consoles have a way to allocate more resources based on given metrics and based on an available budget. Through the configuration mechanism described above, new computational resources can be made available dynamically to the JobManager.

[[sec:processing-supported-workflow-patterns]]
== Supported workflow patterns

In order to summarise the functionality of our system in terms of workflow management, we revise the list of workflow patterns defined by citet:Aalst2003[] and citet:Russell2004,Russell2004a,Russell2006,Russell2016[] (see also Section <<sec:processing-workflow-patterns>>). In the following table we list each pattern our system supports and how we implement it. This summary can be used as a reference to relate our approach to other workflow management systems.

[cols="9,30,45",frame=none,grid=rows,options="header"]
|===
| Pattern
| Description
| Implementation

3+| _Control-flow patterns_

| WCP-1
| _Sequence_ &ndash;
Execute tasks sequentially
| Our workflow model allows actions to be chained through output/input parameters. Actions will only be executed if all inputs are available and this can only be true if the preceding actions have finished and written their output.

| WCP-2
| _Parallel Split_ &ndash; Execute multiple workflow branches in parallel
| Section <<sec:processing-rule-system>> shows how process chains can be split and executed in parallel.

| WCP-3
| _Synchronisation_ &ndash; Join multiple parallel workflow branches
| Similar to WCP-2: see Section <<sec:processing-rule-system>>. Process chains with predecessors will only be executed if all preceding process chains have finished successfully.

| WCP-11
| _Implicit Termination_ &ndash; Terminate workflow when there is no more work to be done
| The Controller will finish the workflow execution if the Rule System does not produce any more process chains (See Section <<sec:processing-controller>>).

| WCP-12
| _Multiple Instances Without Synchronisation_ &ndash; Multiple instances of the same task can be created. Synchronisation is not necessary.
| Our for-each action creates multiple instances of its sub-actions which can be executed independently (see Section <<sec:processing-workflow>>).

| WCP-13
| _Multiple Instances With a Priori Design Time Knowledge_ &ndash; The number of instances of all actions is already known before the workflow is executed.
| Given one of the variables in our workflow model has a `ListValue` and the for-each action is applied to this variable, then the number of all instances of the for-each action's sub-actions is known in advance.

| WCP-14
| _Multiple Instances With a Priori Runtime Knowledge_ &ndash; The number of instances of all actions can be decided at runtime before these actions are executed.
| Given an action writes a number of files into an output directory, the Processing Connector lists the directory contents and passes the files as available inputs to the Rule System. Subsequent for-each actions can then be applied to this file list.

| WCP-20
| _Cancel Case_ &ndash; The workflow execution can be cancelled.
| The JobManager's HTTP interface allows workflows to be deleted from the database. In such a case the Controller will produce no more process chains for the deleted workflow. The Process Chain Manager will finish the execution of currently running process chains, but stop (or return to standby) as soon as there are no more process chains to be executed in the database.

3+| _Resource patterns_

| R-RF, R-CE
| _Retain Familiar_ &ndash; Allocate a workflow action to the same resource as a preceding one, _Chained Execution_ &ndash; Immediately execute the next action when the preceding one has finished.
| The Rule System creates process chains containing one or more directly connected processing services. It splits them into smaller chains using the constraints described in Section&nbsp;<<sec:processing-rule-system>>. In order to leverage data locality, all services of a process chain are executed on the same compute node.

| R-CBA, R-SHQ
| _Capability-based Allocation_ &ndash; Allocate actions based on capabilities offered by a resource, _Shortest Queue_ &ndash; Allocate an action to the resource with the shortest work queue.
| The Process Chain Manager uses a _Capability-based Shortest Queue_ algorithm (see Section&nbsp;<<sec:processing-process-chain-manager>>).

| R-DBAS
| _Distribution by Allocation &ndash; Single Resource_ &ndash; Directly allocate an action to a resource.
| The Process Chain Manager sends a process chain to a single compute node for execution. It only tries another one if the node is currently unavailable. Once the process chain has successfully been transferred to the node, it is expected to be executed. No other node will be tried, even if the execution fails.

| R-DE, R-LD
| _Distribution on Enablement_ &ndash; Actions are allocated to resources as soon as they are ready for execution, _Late Distribution_ &ndash; Allocate resources at a later point in time.
| As soon as the Controller has stored a process chain in the JobManager's database, it can be picked up by the Process Chain Manager. If there is a compute node available the Process Chain Manager immediately allocates the process chain to it. Otherwise, it retries the operation later.

| R-D
| _Delegation_ &ndash; A resource delegates work to another one.
| In our case this can happen for environments such as Spark or Hadoop clusters. The compute nodes registered with the JobManager are those that run the cluster manager, but not necessarily those that do the work. The cluster manager may distribute work to other nodes in the Cloud unknown to the JobManager.

| R-E, &nbsp; &nbsp; R-SD
| _Escalation_ &ndash; An action is allocated to another resource than the one it has been allocated before, _Deallocation_ &ndash; An action is deallocated from a resource.
| The Process Chain Manager can allocate a process chain to another compute node if the selected one is currently unavailable. Special care is taken to prevent the process chain to be allocated to the same compute node again.

| R-CA
| _Commencement of Allocation_ &ndash; Resources execute allocated actions immediately.
| The Processing Connector starts the execution of a process chain immediately after is has received it.

| R-SE
| _Simultaneous Execution_ &ndash; A resource can execute multiple actions at the same time.
| The Processing Connector can run multiple process chains in parallel to make best use of available resources.

3+| _Data patterns_

| D-1
| _Task Data_ &ndash; Data elements can be defined by task
| Workflow actions can have parameters.

| D-2
| _Block Data_ &ndash; Data elements can be defined by block (or sub-workflow)
| Our for-each actions have sub-actions. All of them can access the data the for-each action is applied to. A list of sub-actions basically is a sub-workflow. In addition, in Chapter <<chap:workflow-modelling>> we introduce `with` blocks which directly implement this pattern.

| D-3
| _Scope Data_ &ndash; Some data elements are only accessible by a subset of tasks.
| There is no direct notion of a scope in the JobManager. The Domain-Specific Language we introduce in Chapter <<chap:workflow-modelling>>, however, has variable scopes.

| D-4
| _Multiple Instance Data_ &ndash; Every instance of a task can maintain its own data.
| We support this when we execute a processing service in a separate environment such as a Docker container. In this environment a service can create arbitrary files without interfering with other services or service instances.

| D-5, D-6
| _Case Data_ &ndash; All tasks in a workflow instance can access the same data, _Workflow Data_ &ndash; Data can be shared between workflow instances.
| Workflow inputs and outputs are stored in a distributed file system and persist across workflow executions. Tasks in a workflow can access the same input data. Output data of one workflow can become input data of a subsequent one.

| D-7
| _Environment Data_ &ndash; Tasks can access files in the external operating system.
| This is supported, for example, if we execute a processing service in a Docker container. Through the service metadata attribute '`runtime_args`' (see Section&nbsp;<<sec:processing-service-metadata>>) we can mount files or directories from the external operating system to the container. Also, if we execute processing services directly without a container, they can access any data in the local file system.

| D-8
| _Data Interaction &ndash; Task to Task_ &ndash; Data elements can be passed from one task to another.
| Actions in our workflow model are connected through output and input variables. The same applies to executables in the process chain model.

| D-9, D-10, D-11, D-12
| _Data Interaction &ndash; Block Task to Sub-Workflow Decomposition_, _Sub-Workflow Decomposition to Block Task_, _to Multiple Instance Task_, _from Multiple Instance Task_
| These patterns are implemented by our for-each action. We can pass data to this action which then distributes it to its sub-actions. The results of the sub-actions is collected and can then be passed to subsequent actions.

| D-14, D-15
| _Data Interaction &ndash; Task to Environment &ndash; Push-Oriented_, _Environment to Task &ndash; Pull-Oriented_ &ndash; A task can pass data to resources or services in the environment, and can request data from them.
| Processing services write to the distributed file system and read from it.

| D-24
| _Data Interaction &ndash; Environment to Workflow &ndash; Push-Oriented_ &ndash; Environment data can be passed to a workflow.
| This relates to the datasets a workflow should be applied to. These are basically the input variables in the workflow model which are defined at the time the workflow execution starts.

| D-26
| _Data Transfer by Value &ndash; Incoming_ &ndash; Workflow components may receive input by value.
| Actions in our workflow model can have parameters which are defined by variables and values.

| D-28
| _Data Transfer &ndash; Copy In/Copy Out_ &ndash; A workflow component copies data into its address space and writes back the final results.
| This is the usual case with our processing services. They read datasets from the distributed file system, transform it, and write back the results.

| D-29, D-30
| _Data Transfer by Reference &ndash; Unlocked and With Lock_ &ndash; Data can be communicated between workflow components by reference without copying the data.
| We use file names to communicate the location of datasets to the workflow actions. Whether concurrent data access is protected by a lock or not is undefined, but variables in the Domain-Specific Language in Chapter <<chap:workflow-modelling>> are immutable. Therefore locks are not required, because there only are concurrent reads. Writes always happen exclusively to new files.

| D-31, D-32
| _Data Transformation &ndash; Input and Output_ &ndash; The possibility to transform input and output data prior or after the execution of a workflow component.
| As described in Section <<sec:processing-rule-system>> the Rule System may insert additional processing services before or after a service in a process chain to transform its input or output. This depends on the service metadata. For example, the Rule System may add a data conversion service between service A and B if A's output data type is incompatible to B's input data type.

|===

[[sec:processing-summary]]
== Summary

In this chapter we discussed how our system performs distributed data processing based on workflows. We first described background on workflow management systems and then compared our approach to related work. We then gave an overview of the software architecture of our workflow management service, the JobManager, and then described its internal data models and components in detail. Finally, we discussed fault tolerance, scalability as well as elasticity, and summarised the functionality of our system using well-defined workflow patterns.

One of the main benefits of our JobManager is that it can execute processing services with arbitrary interfaces. We presented a lightweight approach to describe the interface of a service with JSON-based service metadata. Based on this metadata, the JobManager can generate command-line calls for the services and orchestrate them to workflows. Developers can integrate their services into our system without fundamental modifications. They just need to create an interface description. The JobManager takes care of deploying the services and parallelising them in the Cloud.

Our approach to workflow management has a significant advantage over other systems that support the execution of workflows in a distributed environment. Since the number of instances of a processing service can, in our case, depend on the results of a preceding one, we support dynamic workflow execution without a priori design-time knowledge. Other workflow management systems require complex workarounds to implement this behaviour.

Internally, the JobManager makes use of rule-based system that is configurable and allows us to adapt the workflow execution to different domains. A typical scenario from the geospatial domain is, for example, that a certain user does not have access to a data set or a processing algorithm because of a missing licence. We can accommodate for this by adding a rule to our rule-based system to prevent the data set from being used as input or to disallow using the processing algorithm (and probably find an alternative). Another example from the geospatial domain is that users often prefer specific data sets or algorithms over others (e.g. due to better quality, better reputation, etc.). Such preferences are user-specific and can be implemented with our rule-based system.

In the following chapter we further discuss the configurability and adaptability of our system to specific use cases. We present a Domain-Specific Language with which users can control the behaviour of our system by specifying processing workflows.
